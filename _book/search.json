[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "TAREA PROYECTO - BOOK LCC",
    "section": "",
    "text": "Introducción\nSon múltiples las técnicas sobre análisis de datos que hemos aprendido a lo largo de la asignatura de “Laboratorio de Computación Científica”, entre las cuales podemos mencionar: análisis de conjuntos de datos con dplyr, visualización de datos con ggplot o reglas de asociación de un dataset con apriori. Se que en este pequeño listado dejo atrás muchas de las herramientas que hemos ido usando a lo largo de la asignatura, pero sin duda en este proyecto abordaremos sus aplicaciones.\nEl análisis de datos y las técnicas asociadas tienen una amplia gama de aplicaciones en diversos campos, lo que los convierte en herramientas fundamentales para la toma de decisiones informadas y la generación de conocimiento. Entre ellas podemos destacar: investigación científica (identificar patrones y analizar resultados experimentales), sectores empresariales (comprender el comportamiento del mercado en ciertos ámbitos), salud y medicina (predecir enfermedades) o marketing (identificar perfiles destacados de clientes).\nSin embargo, nosotros nos iremos un poco más a terreno “moderno” y actual. Hablamos de Instagram. ¿Quién no utiliza esta reconocidísima red social hoy en día? Y sobretodo, enfocados a lo que nos concierne a nuestro proyecto, ¿quién no ha sospechado alguna vez de un usuario desconocido, que por alguna razón extraña comienza a seguirnos?. Aquí centraremos nuestra investigación. Trataremos de analizar un amplio dataset de la plataforma Kaggle.\nSe trata concretamente de un dataset que contiene información de 696 usuarios de Instagram, para los cuales proporciona un total de 12 atributos, entre los cuales destacan: nums/length username, fullname words, name==username , #follows o fake (el más importante o como se le suele llamar en el contexto de Machine Learning, la inferencia, es decir, aquello que el modelo predice). Es precisamente en este último campo en el que realmente el dataset está centrado, ya que en la propia documentación se indica que se pretende construir un modelo de aprendizaje automático fiable, que aprenda del conjunto de datos (training set), y sea capaz tras este proceso de predecir para ciertas entradas (testing data) que representen a usuario no conocidos anteriormente por el modelo, si se tratan de cuentas verdaderas o falsas. Aunque en nuestro caso el proyecto se aleja un poco de las manos del ML (Machine Learning) y solo se pretende usar el dataset para aplicarlo a lo que nos concierne, en mi caso trataré de incluir alguna sección que este orientada a este campo.\n\n\n\n\n\nCabe mencionar por último, que para la realización del trabajo haremos uso de Quarto, una poderosa herramienta diseñada para la creación y gestión de libros interactivos y dinámicos. Con su enfoque centrado en el usuario y su versatilidad, Quarto permite a los creadores transformar ideas en conocimiento de manera eficiente y efectiva. Los books son una forma eficaz de compartir conocimiento, desde documentos técnicos y manuales de referencia hasta tutoriales interactivos y libros educativos.\nUna vez hemos descrito con detalle el problema a abordar, podemos pasar al primer punto del proyecto, que consistirá en un análisis explotario de datos centrados en nuestro dataset."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n1.0.1 Aver que sale\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "analisisexploratorio.html",
    "href": "analisisexploratorio.html",
    "title": "1  Análisis exploratorio de datos",
    "section": "",
    "text": "Nos encontramos ante la primera sección de nuestro book… breve introduccion…\nLo primero que debemos de hacer es, suponiendo que ya hemos descargado el dataset de manera manual desde la plataforma de Kaggle, debemos proceder a importarlo en nuestro entorno. Para ello haré uso de readr, un paquete de R que permite importar archivos con extension CSV, es decir, un formato típico de datasets o tablas que contienen una determinada información a partir de ciertas filas y columnas. Para ello usaremos en concreto read_csv.\n\nlibrary(readr)\ntrain &lt;- read_csv(\"datasets/train.csv\")\ntest &lt;- read_csv(\"datasets/test.csv\")\n\nComo ya comentamos más arriba, debido al origen de la finalidad que tenía el artículo del cual hemos extraido el dataset, se presentaba el dataset estructurado en 2 de cara al entrenamiento del modelo que se trataba de construir en el mismo. Nosotros lo que haremos será buscar alguna función que permita concatenar por filas varios conjuntos de datos. La elección perfecta será rbind. No se debe confundir con cbind, la cual realiza una acción similar a la anterior, pero por columnas, por lo que nuestro dataset final quedaría con 24 atributos, aunque no buscamos eso…\n\nall_data &lt;- rbind(train, test)"
  },
  {
    "objectID": "visualizaciondatos.html",
    "href": "visualizaciondatos.html",
    "title": "2  Visualización de datos",
    "section": "",
    "text": "A todos siempre nos ha gustado apreciar todas las “mates” por los ojos, ¿verdad? Y es que ver una gráfica que te muestre de manera clara y concisa como evoluciona cierta variable a lo largo del tiempo, cómo 2 o más variables están correlacionadas cuando no lo parecía o cúales son los máximos que toma una variable a partir de un histograma, es mucho más divertido que ver tablas y tablas llenas de números y atributos. Podemos estar tranquilos porque este apartado del book evitará esto último.\nY es que la visualización de datos nos permite ir más allá de las simples cifras y estadísticas, brindándonos una forma poderosa de comprender y comunicar patrones, tendencias y relaciones en nuestros datos. Desde gráficos simples hasta visualizaciones interactivas y sofisticadas, las herramientas de visualización nos permiten explorar la información de manera intuitiva y revelar insights que pueden pasar desapercibidos en tablas de datos estáticas.\nAl representar nuestros datos de manera visual, podemos identificar patrones complejos, detectar anomalías, y acciones similares. Ya sea que estemos explorando datos para comprender el comportamiento de los usuarios en una plataforma digital, analizando tendencias de ventas en un negocio, investigando patrones climáticos a lo largo del tiempo o, en nuestro caso, viendo cualidades y/o atributos de perfiles fake de Instagram, la visualización de datos nos brinda una ventana clara y concisa hacia el mundo de la información que nos rodea.\nEn esta sección del libro, exploraremos diversas técnicas y herramientas de visualización de datos que nos permitirán sacar el máximo provecho de nuestro dataset. Desde gráficos simples hasta visualizaciones interactivas, aprenderemos cómo seleccionar y construir visualizaciones efectivas que nos ayuden a contar historias convincentes y a extraer insights valiosos de nuestros datos. ¡Vamos a ello!"
  },
  {
    "objectID": "reglasasociacion.html",
    "href": "reglasasociacion.html",
    "title": "3  Reglas de asociación",
    "section": "",
    "text": "A menudo nos encontramos con conjuntos de datos complejos que contienen una gran cantidad de información valiosa. Sin embargo, entre las vastas filas y columnas de números y atributos, a menudo se esconden patrones y relaciones que no son evidentes a simple vista. Aquí es donde entran en juego las reglas de asociación: una potente técnica de minería de datos que nos permite descubrir conexiones ocultas y asociaciones significativas entre los elementos de nuestros datos.\nLas reglas de asociación nos permiten identificar patrones frecuentes, revelar relaciones interesantes y descubrir insights que de otro modo podrían pasar desapercibidos. Desde la cesta de la compra en el supermercado hasta el comportamiento del usuario en sitios web, las reglas de asociación han demostrado ser invaluable para comprender el comportamiento humano y las relaciones entre los elementos. Algunas de las aplicaciones más reconocidas dentro de este mundo son marketing y ventas, análisis de cestas de compra (Market Basket Analysis), recomendación de productos, etc.\n\n  \n\nPara sumergirnos de lleno en reglas de asociación, como no podía ser de otra manera haremos uso de arules, que nos ofrece un conjunto diverso de herramientas para desentrañar los secretos de nuestros datos y obtener insights accionables para la toma de decisiones. Con más de 25000 descargas mensuales, Michael Hahsler logró desarrollar un extenso paquete que hoy en día es usado en numerosas herramientas de Data Mining. Si él nos hizo el favor de crearlo, nosotros nos vemos en la obligación de darle uso.\n\nlibrary(arules)\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'arules'\n\n\nThe following objects are masked from 'package:base':\n\n    abbreviate, write\n\n# Como es costumbre, cargamos el dataset\nlibrary(readr)\ntrain &lt;- read_csv(\"datasets/train.csv\")\n\nRows: 576 Columns: 12\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntest &lt;- read_csv(\"datasets/test.csv\")\n\nRows: 120 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nall_data &lt;- rbind(train, test)\n\nSin embargo, ahora nos encontramos con un problema, y es que arules y su algoritmos están diseñados para trabajar con datos categóricos o binarios. Si los datos son continuos, como los números enteros o flotantes, es necesario discretizarlos en rangos o categorías. Por ello, debemos de hacer uso de cut(), para convertir cada atributo de nuestro dataset en uno discretizado…\n\nall_data_transactions &lt;- all_data\n\nall_data_transactions$`profile pic` &lt;- cut(all_data$`profile pic`, breaks = 2,labels = c(\"No tiene\", \"Tiene\"),include.lowest = TRUE)\n\nall_data_transactions$`fullname words` &lt;- cut(all_data$`fullname words`, breaks = 3,labels = c(\"Bajo\", \"Medio\", \"Alto\"),include.lowest = TRUE)\n\nall_data_transactions$`nums/length fullname` &lt;- cut(all_data$`nums/length fullname`, breaks = 3,labels = c(\"Bajo\", \"Medio\", \"Alto\"),include.lowest = TRUE)\n\nall_data_transactions$`nums/length username` &lt;- cut(all_data$`nums/length username`, breaks = 3, labels = c(\"Bajo\", \"Medio\", \"Alto\"), include.lowest = TRUE)\n\nall_data_transactions$`description length` &lt;- cut(all_data$`description length`, breaks = 3, labels = c(\"Bajo\", \"Medio\", \"Alto\"), include.lowest = TRUE)\n\nall_data_transactions$`external URL` &lt;- cut(all_data$`external URL`, breaks = 2, labels = c(\"No tiene\", \"Tiene\"), include.lowest = TRUE)\n\nall_data_transactions$private &lt;- cut(all_data$private, breaks = 2, labels = c(\"No\", \"Sí\"), include.lowest = TRUE)\n\nall_data_transactions$fake &lt;- cut(all_data$fake, breaks = 2, labels = c(\"No\", \"Sí\"), include.lowest = TRUE)\n\nall_data_transactions$`name==username` &lt;- cut(all_data$`name==username`, breaks = 2, labels = c(\"No\", \"Si\"), include.lowest = TRUE)\n\nall_data_transactions$`#posts` &lt;- cut(all_data$`#posts`, breaks = 3, labels = c(\"Bajo\", \"Medio\", \"Alto\"), include.lowest = TRUE)\n\nall_data_transactions$`#followers` &lt;- cut(all_data$`#followers`, breaks = 3, labels = c(\"Bajo\", \"Medio\", \"Alto\"), include.lowest = TRUE)\n\nall_data_transactions$`#follows` &lt;- cut(all_data$`#follows`, breaks = 3, labels = c(\"Bajo\", \"Medio\", \"Alto\"), include.lowest = TRUE)\n\nUna vez hemos discretizado cada una de las variables o atributos que componen nuestro dataset, con as(transactions) pasamos el conjunto total de datos a transacciones, para poder trabajar con reglas de asociación.\n\nall_data_transactions &lt;- as(all_data_transactions, \"transactions\")\ninspect(all_data_transactions[1:2])\n\n    items                        transactionID\n[1] {profile pic=Tiene,                       \n     nums/length username=Bajo,               \n     fullname words=Bajo,                     \n     nums/length fullname=Bajo,               \n     name==username=No,                       \n     description length=Medio,                \n     external URL=No tiene,                   \n     private=No,                              \n     #posts=Bajo,                             \n     #followers=Bajo,                         \n     #follows=Bajo,                           \n     fake=No}                                1\n[2] {profile pic=Tiene,                       \n     nums/length username=Bajo,               \n     fullname words=Bajo,                     \n     nums/length fullname=Bajo,               \n     name==username=No,                       \n     description length=Bajo,                 \n     external URL=No tiene,                   \n     private=No,                              \n     #posts=Bajo,                             \n     #followers=Bajo,                         \n     #follows=Bajo,                           \n     fake=No}                                2\n\n\nUna vez hemos preparado nuestro conjunto de datos, ya podemos pasar a identificar patrones frecuentes, revelar relaciones interesantes y descubrir insights. Para ello, el trabajo con arules se hace muy sencilla. Usando simplemente la función apriori pasándole por parámetro el sesgo de confianza y soporte que queremos para las reglas, podemos obtenerlas de manera rápida y sencilla. Un poco de la matemática que hay de fondo en apriori…\nEl soporte de un conjunto de elementos \\(X\\), denotado como \\(Sop(X)\\), se define como la proporción de filas en un conjunto de datos \\(D\\) que contienen todos los elementos de \\(X\\). Matemáticamente, se expresa como:\n\\[\n\\text{Sop}(X) = \\frac{|X|}{|D|}\n\\]\nLa confianza de una regla de asociación \\(( X \\rightarrow Y )\\), denotada como \\(\\text{Conf}(X \\rightarrow Y)\\), se define como la proporción de filas en un conjunto de datos \\(( D )\\) que contienen tanto \\(( X )\\) como \\(( Y )\\), en relación con las filas que contienen \\(( X )\\). Matemáticamente, se expresa como:\n\\[\n\\text{Conf}(X \\rightarrow Y) = \\frac{\\text{Sop}(X \\cup Y)}{\\text{Sop}(X)}\n\\]\n\nreglas &lt;- apriori(all_data_transactions,\n                  parameter = list(supp = 0.5, conf = 0.8))\n\n\nlength(reglas)\n\n[1] 2846\n\ninspect(reglas[1:10])\n\n     lhs          rhs                         support   confidence coverage\n[1]  {}        =&gt; {description length=Bajo}   0.8189655 0.8189655  1.0     \n[2]  {}        =&gt; {external URL=No tiene}     0.8864943 0.8864943  1.0     \n[3]  {}        =&gt; {nums/length fullname=Bajo} 0.9511494 0.9511494  1.0     \n[4]  {}        =&gt; {#follows=Bajo}             0.9583333 0.9583333  1.0     \n[5]  {}        =&gt; {name==username=No}         0.9640805 0.9640805  1.0     \n[6]  {}        =&gt; {fullname words=Bajo}       0.9827586 0.9827586  1.0     \n[7]  {}        =&gt; {#followers=Bajo}           0.9942529 0.9942529  1.0     \n[8]  {}        =&gt; {#posts=Bajo}               0.9971264 0.9971264  1.0     \n[9]  {fake=Sí} =&gt; {external URL=No tiene}     0.5000000 1.0000000  0.5     \n[10] {fake=Sí} =&gt; {#followers=Bajo}           0.5000000 1.0000000  0.5     \n     lift     count\n[1]  1.000000 570  \n[2]  1.000000 617  \n[3]  1.000000 662  \n[4]  1.000000 667  \n[5]  1.000000 671  \n[6]  1.000000 684  \n[7]  1.000000 692  \n[8]  1.000000 694  \n[9]  1.128039 348  \n[10] 1.005780 348  \n\n\nAunque resulte extraño, algunas de las reglas que se nos han generado (concretamente las 8 primeras), presentan el conjunto vacío a la izquierda, pero no hay por qué asustarse. Esto podría ser solucionado simplemente añadiendo un parámetro más a parameter, que sería minlen = 2. Sin embargo, ni siquiera es necesario porque las reglas que contienen lhs vacío (parte izquierda), son igualmente útiles porque identifican patrones de comportamiento o relaciones entre elementos que ocurren de forma independiente de otros elementos. Esto significa que estas reglas capturan asociaciones fuertes entre un elemento o atributo y otro, sin depender de la presencia o ausencia de otros elementos.\nSi quiseramos hacer un resumen cuantitativo de las reglas que hemos extraido en el paso anterior, podríamos usar summary().\n\nsummary(reglas)\n\nset of 2846 rules\n\nrule length distribution (lhs + rhs):sizes\n  1   2   3   4   5   6   7   8 \n  8  82 328 704 863 604 222  35 \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00    4.00    5.00    4.83    6.00    8.00 \n\nsummary of quality measures:\n    support         confidence        coverage           lift       \n Min.   :0.5000   Min.   :0.8000   Min.   :0.5000   Min.   :0.9400  \n 1st Qu.:0.5460   1st Qu.:0.9487   1st Qu.:0.5690   1st Qu.:0.9974  \n Median :0.6164   Median :0.9744   Median :0.6695   Median :1.0007  \n Mean   :0.6515   Mean   :0.9568   Mean   :0.6827   Mean   :1.0094  \n 3rd Qu.:0.7381   3rd Qu.:0.9945   3rd Qu.:0.7716   3rd Qu.:1.0095  \n Max.   :0.9971   Max.   :1.0000   Max.   :1.0000   Max.   :1.1637  \n     count      \n Min.   :348.0  \n 1st Qu.:380.0  \n Median :429.0  \n Mean   :453.4  \n 3rd Qu.:513.8  \n Max.   :694.0  \n\nmining info:\n                  data ntransactions support confidence\n all_data_transactions           696     0.5        0.8\n                                                                            call\n apriori(data = all_data_transactions, parameter = list(supp = 0.5, conf = 0.8))\n\n\nDonde podemos ver que el output muestra un conjunto de 2846 reglas de asociación. La distribución de la longitud de las reglas revela que la mayoría tienen entre 4 y 6 elementos. Las medidas de calidad incluyen soporte, confianza, cobertura y lift, proporcionando información sobre la frecuencia y fiabilidad de las reglas. El conteo máximo indica que la regla más frecuente se observó en 694 transacciones.\nPodemos pasar ahora a mostrar ejemplos simples de usos del paquete arules. Podemos empezar con las funciones que nos permiten quedarnos con la parte izquierda y derecha de las reglas que queramos.\n\nreglaConcreta &lt;- reglas[1243]\ninspect(reglaConcreta)\n\n    lhs                             rhs                 support confidence  coverage      lift count\n[1] {profile pic=Tiene,                                                                             \n     nums/length username=Bajo,                                                                     \n     fullname words=Bajo,                                                                           \n     nums/length fullname=Bajo}  =&gt; {#followers=Bajo} 0.5617816  0.9898734 0.5675287 0.9955952   391\n\ninspect(lhs(reglaConcreta))\n\n    items                       \n[1] {profile pic=Tiene,         \n     nums/length username=Bajo, \n     fullname words=Bajo,       \n     nums/length fullname=Bajo} \n\ninspect(rhs(reglaConcreta))\n\n    items            \n[1] {#followers=Bajo}\n\n\nUna manera util de ver todo lo que se puede hacer con un determinado objeto en R, es usar str(objeto). Esto nos produce un output con todos los atributos y metodos de dicho objeto (como en programación orientada a objetos). Por ejemplo, si quisieramos saber qué podemos hacer con el conjunto de reglas que hemos extraido anteriormente…\n\nstr(reglas)\n\nFormal class 'rules' [package \"arules\"] with 4 slots\n  ..@ lhs    :Formal class 'itemMatrix' [package \"arules\"] with 3 slots\n  .. .. ..@ data       :Formal class 'ngCMatrix' [package \"Matrix\"] with 5 slots\n  .. .. .. .. ..@ i       : int [1:10899] 30 30 30 29 18 18 18 18 18 18 ...\n  .. .. .. .. ..@ p       : int [1:2847] 0 0 0 0 0 0 0 0 0 1 ...\n  .. .. .. .. ..@ Dim     : int [1:2] 31 2846\n  .. .. .. .. ..@ Dimnames:List of 2\n  .. .. .. .. .. ..$ : NULL\n  .. .. .. .. .. ..$ : NULL\n  .. .. .. .. ..@ factors : list()\n  .. .. ..@ itemInfo   :'data.frame':   31 obs. of  3 variables:\n  .. .. .. ..$ labels   : chr [1:31] \"profile pic=No tiene\" \"profile pic=Tiene\" \"nums/length username=Bajo\" \"nums/length username=Medio\" ...\n  .. .. .. ..$ variables: Factor w/ 12 levels \"#followers\",\"#follows\",..: 12 12 10 10 10 7 7 7 9 9 ...\n  .. .. .. ..$ levels   : Factor w/ 8 levels \"Alto\",\"Bajo\",..: 5 8 2 3 1 2 3 1 2 3 ...\n  .. .. ..@ itemsetInfo:'data.frame':   0 obs. of  0 variables\n  ..@ rhs    :Formal class 'itemMatrix' [package \"arules\"] with 3 slots\n  .. .. ..@ data       :Formal class 'ngCMatrix' [package \"Matrix\"] with 5 slots\n  .. .. .. .. ..@ i       : int [1:2846] 13 16 8 26 11 5 23 20 16 23 ...\n  .. .. .. .. ..@ p       : int [1:2847] 0 1 2 3 4 5 6 7 8 9 ...\n  .. .. .. .. ..@ Dim     : int [1:2] 31 2846\n  .. .. .. .. ..@ Dimnames:List of 2\n  .. .. .. .. .. ..$ : NULL\n  .. .. .. .. .. ..$ : NULL\n  .. .. .. .. ..@ factors : list()\n  .. .. ..@ itemInfo   :'data.frame':   31 obs. of  3 variables:\n  .. .. .. ..$ labels   : chr [1:31] \"profile pic=No tiene\" \"profile pic=Tiene\" \"nums/length username=Bajo\" \"nums/length username=Medio\" ...\n  .. .. .. ..$ variables: Factor w/ 12 levels \"#followers\",\"#follows\",..: 12 12 10 10 10 7 7 7 9 9 ...\n  .. .. .. ..$ levels   : Factor w/ 8 levels \"Alto\",\"Bajo\",..: 5 8 2 3 1 2 3 1 2 3 ...\n  .. .. ..@ itemsetInfo:'data.frame':   0 obs. of  0 variables\n  ..@ quality:'data.frame': 2846 obs. of  5 variables:\n  .. ..$ support   : num [1:2846] 0.819 0.886 0.951 0.958 0.964 ...\n  .. ..$ confidence: num [1:2846] 0.819 0.886 0.951 0.958 0.964 ...\n  .. ..$ coverage  : num [1:2846] 1 1 1 1 1 1 1 1 0.5 0.5 ...\n  .. ..$ lift      : num [1:2846] 1 1 1 1 1 ...\n  .. ..$ count     : int [1:2846] 570 617 662 667 671 684 692 694 348 348 ...\n  ..@ info   :List of 5\n  .. ..$ data         : symbol all_data_transactions\n  .. ..$ ntransactions: int 696\n  .. ..$ support      : num 0.5\n  .. ..$ confidence   : num 0.8\n  .. ..$ call         : chr \"apriori(data = all_data_transactions, parameter = list(supp = 0.5, conf = 0.8))\"\n\n\nY ahora usamos las cosas que vemos en el ouput\n\nhead(reglas@quality$confidence)\n\n[1] 0.8189655 0.8864943 0.9511494 0.9583333 0.9640805 0.9827586\n\nreglas@lhs@itemInfo$labels\n\n [1] \"profile pic=No tiene\"       \"profile pic=Tiene\"         \n [3] \"nums/length username=Bajo\"  \"nums/length username=Medio\"\n [5] \"nums/length username=Alto\"  \"fullname words=Bajo\"       \n [7] \"fullname words=Medio\"       \"fullname words=Alto\"       \n [9] \"nums/length fullname=Bajo\"  \"nums/length fullname=Medio\"\n[11] \"nums/length fullname=Alto\"  \"name==username=No\"         \n[13] \"name==username=Si\"          \"description length=Bajo\"   \n[15] \"description length=Medio\"   \"description length=Alto\"   \n[17] \"external URL=No tiene\"      \"external URL=Tiene\"        \n[19] \"private=No\"                 \"private=Sí\"                \n[21] \"#posts=Bajo\"                \"#posts=Medio\"              \n[23] \"#posts=Alto\"                \"#followers=Bajo\"           \n[25] \"#followers=Medio\"           \"#followers=Alto\"           \n[27] \"#follows=Bajo\"              \"#follows=Medio\"            \n[29] \"#follows=Alto\"              \"fake=No\"                   \n[31] \"fake=Sí\"                   \n\nreglas@info$ntransactions\n\n[1] 696\n\n\nArules también nos permite realizar un detallado filtrado sobre un conjunto de reglas. Esto es útil en muchas ocasiones. Por ejemplo, imaginemosno que tenemos un dataset que hemos convertido a transactions y que corresponden a compras que se han realizado en Mercadona. Quizás, el jefe está interesado en conocer que relaciones existen en las compras de los clientes, y para ello manda a sus ingenieros a qué hagan uso de arules para extraer conocimiento. Concretamente, los especialistas usarán subset. La manera de usarlo es:\n\nreglas.sub1 &lt;- subset(reglas,\n                      subset = lhs %in% c(\"name==username=No\",\"#followers=Medio\"))\n\ninspect(reglas.sub1[100:110])\n\n     lhs                             rhs                           support confidence  coverage      lift count\n[1]  {profile pic=Tiene,                                                                                       \n      name==username=No,                                                                                       \n      #follows=Bajo}              =&gt; {nums/length username=Bajo} 0.5416667  0.8177874 0.6623563 1.1182319   377\n[2]  {nums/length username=Bajo,                                                                               \n      name==username=No,                                                                                       \n      #follows=Bajo}              =&gt; {profile pic=Tiene}         0.5416667  0.8038380 0.6738506 1.1302449   377\n[3]  {profile pic=Tiene,                                                                                       \n      nums/length username=Bajo,                                                                               \n      name==username=No}          =&gt; {fullname words=Bajo}       0.5589080  0.9725000 0.5747126 0.9895614   389\n[4]  {profile pic=Tiene,                                                                                       \n      fullname words=Bajo,                                                                                     \n      name==username=No}          =&gt; {nums/length username=Bajo} 0.5589080  0.8224101 0.6795977 1.1245530   389\n[5]  {nums/length username=Bajo,                                                                               \n      fullname words=Bajo,                                                                                     \n      name==username=No}          =&gt; {profile pic=Tiene}         0.5589080  0.8020619 0.6968391 1.1277476   389\n[6]  {profile pic=Tiene,                                                                                       \n      nums/length username=Bajo,                                                                               \n      name==username=No}          =&gt; {#followers=Bajo}           0.5689655  0.9900000 0.5747126 0.9957225   396\n[7]  {profile pic=Tiene,                                                                                       \n      name==username=No,                                                                                       \n      #followers=Bajo}            =&gt; {nums/length username=Bajo} 0.5689655  0.8232848 0.6910920 1.1257490   396\n[8]  {nums/length username=Bajo,                                                                               \n      name==username=No,                                                                                       \n      #followers=Bajo}            =&gt; {profile pic=Tiene}         0.5689655  0.8048780 0.7068966 1.1317073   396\n[9]  {profile pic=Tiene,                                                                                       \n      nums/length username=Bajo,                                                                               \n      name==username=No}          =&gt; {#posts=Bajo}               0.5718391  0.9950000 0.5747126 0.9978674   398\n[10] {profile pic=Tiene,                                                                                       \n      name==username=No,                                                                                       \n      #posts=Bajo}                =&gt; {nums/length username=Bajo} 0.5718391  0.8240166 0.6939655 1.1267496   398\n[11] {nums/length username=Bajo,                                                                               \n      name==username=No,                                                                                       \n      #posts=Bajo}                =&gt; {profile pic=Tiene}         0.5718391  0.8056680 0.7097701 1.1328181   398\n\n\nSe queda con reglas que en su izquierda contienen o “name==username” o “followers = Medio”.\n\nreglas.sub2 &lt;- subset(reglas,\n                      subset = lhs %ain% c(\"fullname words=Bajo\",\"#followers=Bajo\"))\ninspect(reglas.sub2[1:10])\n\n     lhs                       rhs                           support confidence  coverage      lift count\n[1]  {fullname words=Bajo,                                                                               \n      #followers=Bajo}      =&gt; {description length=Bajo}   0.8045977  0.8235294 0.9770115 1.0055728   560\n[2]  {fullname words=Bajo,                                                                               \n      #followers=Bajo}      =&gt; {external URL=No tiene}     0.8692529  0.8897059 0.9770115 1.0036228   605\n[3]  {fullname words=Bajo,                                                                               \n      #followers=Bajo}      =&gt; {nums/length fullname=Bajo} 0.9281609  0.9500000 0.9770115 0.9987915   646\n[4]  {fullname words=Bajo,                                                                               \n      #followers=Bajo}      =&gt; {#follows=Bajo}             0.9382184  0.9602941 0.9770115 1.0020460   653\n[5]  {fullname words=Bajo,                                                                               \n      #followers=Bajo}      =&gt; {name==username=No}         0.9410920  0.9632353 0.9770115 0.9991233   655\n[6]  {fullname words=Bajo,                                                                               \n      #followers=Bajo}      =&gt; {#posts=Bajo}               0.9755747  0.9985294 0.9770115 1.0014070   679\n[7]  {fullname words=Bajo,                                                                               \n      private=No,                                                                                        \n      #followers=Bajo}      =&gt; {external URL=No tiene}     0.5244253  0.8548009 0.6135057 0.9642487   365\n[8]  {fullname words=Bajo,                                                                               \n      private=No,                                                                                        \n      #followers=Bajo}      =&gt; {nums/length fullname=Bajo} 0.5747126  0.9367681 0.6135057 0.9848801   400\n[9]  {fullname words=Bajo,                                                                               \n      private=No,                                                                                        \n      #followers=Bajo}      =&gt; {#follows=Bajo}             0.5818966  0.9484778 0.6135057 0.9897159   405\n[10] {fullname words=Bajo,                                                                               \n      private=No,                                                                                        \n      #followers=Bajo}      =&gt; {name==username=No}         0.5933908  0.9672131 0.6135057 1.0032494   413\n\n\nSe queda con reglas que en su izquierda contienen “fullname words=Bajo” y “#followers=Bajo”.\n\nreglas.sub3 &lt;- subset(reglas,subset = lhs %pin% \"private=\")\n\nSe queda con reglas que en la izquierda contienen “private=”, sin especificar si es si o no. (por ello es un partial matching).\nSi quisieramos ver visualmente las reglas con las que estamos trabajando…\n\nlibrary(arulesViz)\nplot(reglas)\n\nTo reduce overplotting, jitter is added! Use jitter = 0 to prevent jitter.\n\n\n\n\n\nY si quisieramos que el gráfico fuera interactivo…\n\n#Ejecutar en vuestro ordenador\nplot(reglas, engine = \"htmlwidget\")\n\nWarning: Too many rules supplied. Only plotting the best 1000 using 'lift'\n(change control parameter max if needed).\n\n\nTo reduce overplotting, jitter is added! Use jitter = 0 to prevent jitter.\n\n\n\n\n\n\nVamos a probar ahora a ordenar nuestro conjunto de reglas. El support de una regla de asociación indica la frecuencia con la que se observan todos los elementos de la regla en el conjunto de datos. Cuanto mayor sea el support, más común es la regla en los datos. La confianza de una regla indica la probabilidad de que el consecuente ocurra dado que el antecedente está presente. Cuanto mayor sea la confianza, más fuerte es la relación entre el antecedente y el consecuente.\nSi quisieramos ordenar por tanto, nuestra reglas, algunos ejemplos de ello serían:\n\nreglasOrdSup &lt;- sort(reglas, by = \"support\")\ninspect(reglasOrdSup[1:10])\n\n     lhs                                       rhs                   support  \n[1]  {}                                     =&gt; {#posts=Bajo}         0.9971264\n[2]  {}                                     =&gt; {#followers=Bajo}     0.9942529\n[3]  {#followers=Bajo}                      =&gt; {#posts=Bajo}         0.9928161\n[4]  {#posts=Bajo}                          =&gt; {#followers=Bajo}     0.9928161\n[5]  {}                                     =&gt; {fullname words=Bajo} 0.9827586\n[6]  {fullname words=Bajo}                  =&gt; {#posts=Bajo}         0.9798851\n[7]  {#posts=Bajo}                          =&gt; {fullname words=Bajo} 0.9798851\n[8]  {fullname words=Bajo}                  =&gt; {#followers=Bajo}     0.9770115\n[9]  {#followers=Bajo}                      =&gt; {fullname words=Bajo} 0.9770115\n[10] {fullname words=Bajo, #followers=Bajo} =&gt; {#posts=Bajo}         0.9755747\n     confidence coverage  lift      count\n[1]  0.9971264  1.0000000 1.0000000 694  \n[2]  0.9942529  1.0000000 1.0000000 692  \n[3]  0.9985549  0.9942529 1.0014326 691  \n[4]  0.9956772  0.9971264 1.0014326 691  \n[5]  0.9827586  1.0000000 1.0000000 684  \n[6]  0.9970760  0.9827586 0.9999494 682  \n[7]  0.9827089  0.9971264 0.9999494 682  \n[8]  0.9941520  0.9827586 0.9998986 680  \n[9]  0.9826590  0.9942529 0.9998986 680  \n[10] 0.9985294  0.9770115 1.0014070 679  \n\nreglasOrdSup@quality$support[1:10]\n\n [1] 0.9971264 0.9942529 0.9928161 0.9928161 0.9827586 0.9798851 0.9798851\n [8] 0.9770115 0.9770115 0.9755747\n\n\n\nreglasOrdConf &lt;- sort(reglas, by = \"confidence\")\ninspect(reglasOrdConf[1:10])\n\n     lhs                                 rhs                         support\n[1]  {fake=Sí}                        =&gt; {external URL=No tiene}     0.5    \n[2]  {fake=Sí}                        =&gt; {#followers=Bajo}           0.5    \n[3]  {fake=Sí}                        =&gt; {#posts=Bajo}               0.5    \n[4]  {fake=No}                        =&gt; {nums/length fullname=Bajo} 0.5    \n[5]  {external URL=No tiene, fake=Sí} =&gt; {#followers=Bajo}           0.5    \n[6]  {#followers=Bajo, fake=Sí}       =&gt; {external URL=No tiene}     0.5    \n[7]  {external URL=No tiene, fake=Sí} =&gt; {#posts=Bajo}               0.5    \n[8]  {#posts=Bajo, fake=Sí}           =&gt; {external URL=No tiene}     0.5    \n[9]  {#followers=Bajo, fake=Sí}       =&gt; {#posts=Bajo}               0.5    \n[10] {#posts=Bajo, fake=Sí}           =&gt; {#followers=Bajo}           0.5    \n     confidence coverage lift     count\n[1]  1          0.5      1.128039 348  \n[2]  1          0.5      1.005780 348  \n[3]  1          0.5      1.002882 348  \n[4]  1          0.5      1.051360 348  \n[5]  1          0.5      1.005780 348  \n[6]  1          0.5      1.128039 348  \n[7]  1          0.5      1.002882 348  \n[8]  1          0.5      1.128039 348  \n[9]  1          0.5      1.002882 348  \n[10] 1          0.5      1.005780 348  \n\nreglasOrdConf@quality$confidence[1:10]\n\n [1] 1 1 1 1 1 1 1 1 1 1\n\n\nLas reglas que hemos almacenado en reglasOrdConf están ordenadas por confianza, lo cual nos da realmente juego a la hora de extraer información y relaciones ocultas en nuestro dataset. Hemos hecho inspect de las 10 primeras pero, ¿por qué no quedarnos directamente con todas las reglas de nuestro conjunto que tengan confidence igual a 1, por ejemeplo?\n\nreglasAseguradas &lt;- subset(reglasOrdConf, subset = confidence == 1)\nlength(reglasAseguradas)\n\n[1] 45\n\ninspect(reglasAseguradas[1])\n\n    lhs          rhs                     support confidence coverage lift    \n[1] {fake=Sí} =&gt; {external URL=No tiene} 0.5     1          0.5      1.128039\n    count\n[1] 348  \n\n\nSe trata de reglas con confianza máxima. Una confianza de 1 en una regla de asociación significa que el consecuente de la regla siempre ocurre cuando el antecedente está presente en el conjunto de datos. En otras palabras, la confianza del 100% indica una relación perfecta entre el antecedente y el consecuente, lo que significa que cada vez que se cumple el antecedente, también se cumple el consecuente sin excepción. Vamos a extraer conocimiento de dichas reglas.\n\nreglasAseguradas.sub1 &lt;- subset(reglasAseguradas,\n                                subset = lhs %oin% \"fake=Sí\")\ninspect(reglasAseguradas.sub1)\n\n    lhs          rhs                     support confidence coverage lift    \n[1] {fake=Sí} =&gt; {external URL=No tiene} 0.5     1          0.5      1.128039\n[2] {fake=Sí} =&gt; {#followers=Bajo}       0.5     1          0.5      1.005780\n[3] {fake=Sí} =&gt; {#posts=Bajo}           0.5     1          0.5      1.002882\n    count\n[1] 348  \n[2] 348  \n[3] 348  \n\n\nEstas 3 reglas que hemos encontrado nos indican según su confianza que SIEMPRE que la cuenta que estamos tratando es fake, dicha cuenta ni tendrá URL externa, sus seguidores serán un número bajo y tendrá pocas publicaciones compartidas en su cuenta.\n\nreglasAseguradas.sub2 &lt;- subset(reglasAseguradas,\n                                subset = lhs %ain% c(\"external URL=No tiene\",\"fake=Sí\"))\ninspect(reglasAseguradas.sub2)\n\n    lhs                         rhs               support confidence coverage     lift count\n[1] {external URL=No tiene,                                                                 \n     fake=Sí}                =&gt; {#followers=Bajo}     0.5          1      0.5 1.005780   348\n[2] {external URL=No tiene,                                                                 \n     fake=Sí}                =&gt; {#posts=Bajo}         0.5          1      0.5 1.002882   348\n[3] {external URL=No tiene,                                                                 \n     #followers=Bajo,                                                                       \n     fake=Sí}                =&gt; {#posts=Bajo}         0.5          1      0.5 1.002882   348\n[4] {external URL=No tiene,                                                                 \n     #posts=Bajo,                                                                           \n     fake=Sí}                =&gt; {#followers=Bajo}     0.5          1      0.5 1.005780   348\n\n\nLas 4 reglas obtenidas nos muestran como, cuando la cuenta que estamos tratando o de la cual se quiera extraer conocimiento presente una cuenta sin URL existente y que sea falsa, estamos seguros que sus seguidores serán bajos y sus publicaciones también.\nVamos a tratar de encontrar si alguna de las reglas de las cuales partiamos tenía el “atributo inferencia” “fake” en su parte derecha, lo cual sería realmente útil ya que serían reglas que nos daría conocimiento de una serie de premisas que nos llevarían a decidir si la cuenta es fake o verdadera con una cierta confianza.\n\nsubset(reglas,subset = rhs %pin% \"fake=\")\n\nset of 0 rules \n\n\nComo se puede ver en el ouput del chunk, no se encuentra ninguna regla. Podemos probar a generar reglas de nuevo, esta vez tratando de proporcionar parámetros menos restrictivos…\n\nreglas2 &lt;- apriori(all_data_transactions,\n                  parameter = list(supp = 0.5, conf = 0.5))\n\n\nreglas2.sub1 &lt;- subset(reglas2, subset = rhs %pin% \"fake=\")\n\nlength(reglas2.sub1)\n\n[1] 10\n\ninspect(reglas2.sub1)\n\n     lhs                            rhs       support confidence  coverage     lift count\n[1]  {}                          =&gt; {fake=Sí}     0.5  0.5000000 1.0000000 1.000000   348\n[2]  {}                          =&gt; {fake=No}     0.5  0.5000000 1.0000000 1.000000   348\n[3]  {external URL=No tiene}     =&gt; {fake=Sí}     0.5  0.5640194 0.8864943 1.128039   348\n[4]  {#followers=Bajo}           =&gt; {fake=Sí}     0.5  0.5028902 0.9942529 1.005780   348\n[5]  {#posts=Bajo}               =&gt; {fake=Sí}     0.5  0.5014409 0.9971264 1.002882   348\n[6]  {nums/length fullname=Bajo} =&gt; {fake=No}     0.5  0.5256798 0.9511494 1.051360   348\n[7]  {external URL=No tiene,                                                             \n      #followers=Bajo}           =&gt; {fake=Sí}     0.5  0.5667752 0.8821839 1.133550   348\n[8]  {external URL=No tiene,                                                             \n      #posts=Bajo}               =&gt; {fake=Sí}     0.5  0.5658537 0.8836207 1.131707   348\n[9]  {#posts=Bajo,                                                                       \n      #followers=Bajo}           =&gt; {fake=Sí}     0.5  0.5036179 0.9928161 1.007236   348\n[10] {external URL=No tiene,                                                             \n      #posts=Bajo,                                                                       \n      #followers=Bajo}           =&gt; {fake=Sí}     0.5  0.5676998 0.8807471 1.135400   348\n\n\nSi vamos un paso más alla, podemos ser curiosos y fijarnos en las 2 primeras reglas que se nos generan. Dicen que se parte de {} y se llega a “fake=No” y “fake=Si” respectivamente, cada una de ellas con una confianza de 0,5. Por la definición de confianza, sabemos que es el porcentaje con el cual la parte se da en el caso en el que se de la parte izquierda, y si pensamos en el número de samples que tenian los valores de “fake” tiene sentido:\n\nknitr::kable(table(all_data$fake))\n\n\n\n\nVar1\nFreq\n\n\n\n\n0\n348\n\n\n1\n348\n\n\n\n\n\nVolviendo al resto de reglas sin tener en cuenta las 2 primeras, las reglas 3, 4, y 5 sugieren que ciertos atributos como la ausencia de URL externa, un número bajo de seguidores o un número bajo de publicaciones están asociados con una alta probabilidad de que la cuenta sea falsa (“fake=Sí”), el resto son similares. Si nos fijamos, solo existe una única regla con respecto a la presencia de cuentas verdaderas de Instagram. Se trata de de aquellas cuentas que presentan nums/length fullname=Bajo. Como ya hemos comentado a lo largo del book, es algo que ya conocíamos.\nConcluimos así nuestra inmersión en el mundo de las reglas de asociación, donde hemos explorado cómo estas nos permiten descubrir patrones ocultos en nuestros datos, revelando relaciones significativas entre diferentes variables. A través de herramientas como arules, hemos desentrañado los secretos de nuestros conjuntos de datos y hemos obtenido insights valiosos para la toma de decisiones. Ahora nos adentramos en FCA (Análisis de Conceptos Formales por sus siglas en ingles), una potente técnica nos permite explorar las relaciones entre conjuntos de datos desde una perspectiva diferente, centrada en la estructura de conceptos y la jerarquía de atributos."
  },
  {
    "objectID": "fca.html",
    "href": "fca.html",
    "title": "4  FCA",
    "section": "",
    "text": "El Análisis Formal de Conceptos (FCA) es una poderosa técnica de minería de datos que se originó en la década de 1980 como un enfoque para analizar y extraer conocimiento a partir de datos estructurados. FCA combina principios de la teoría de conjuntos, la lógica formal y la teoría de retículas para representar y explorar relaciones entre conjuntos de objetos y atributos en un contexto dado.\n\n  \n\nEsta metodología se centra en la identificación de conceptos fundamentales dentro de un conjunto de datos, donde un concepto se define como un conjunto de objetos que comparten ciertas propiedades o características comunes. A través del proceso de análisis, FCA revela estructuras jerárquicas y relaciones de inclusión entre los conceptos, lo que permite una comprensión más profunda de la información subyacente y facilita la toma de decisiones informadas.\nEl análisis formal de conceptos (FCA) (Wille, 1982; Ganter y Wille, 1999) es una herramienta matemáticamente bien fundamentada y por ello, nos va a ser de gran utilidad en nuestra extracción de patrones y conocimientos acerca de las cuentas de Instagram. Para ello, se hará uso de fcaR, un paquete desarrollado por equipo de investigadores en nuestra universidad que proporciona estructuras de datos que permiten al usuario trabajar sin problemas con contextos formales y conjuntos de implicaciones.\n\nlibrary(fcaR)\nlibrary(readr)\ntrain &lt;- read_csv(\"datasets/train.csv\")\n\nRows: 576 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntest &lt;- read_csv(\"datasets/test.csv\")\n\nRows: 120 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nall_data &lt;- rbind(train, test)\n\nComo nos es necesario tener discretizado nuestro dataset, vamos a reutilizar el código de la sección anterior del book. Concretamente, la parte donde convertiamos en intervalos cada uno de las variables de nuestro dataset…\n\nall_data_transactions &lt;- all_data\n\nall_data_transactions$`fullname words` &lt;- cut(all_data$`fullname words`, breaks = 3,labels = c(\"Bajo\", \"Medio\", \"Alto\"),include.lowest = TRUE)\n\nall_data_transactions$`nums/length fullname` &lt;- cut(all_data$`nums/length fullname`, breaks = 3,labels = c(\"Bajo\", \"Medio\", \"Alto\"),include.lowest = TRUE)\n\nall_data_transactions$`nums/length username` &lt;- cut(all_data$`nums/length username`, breaks = 3, labels = c(\"Bajo\", \"Medio\", \"Alto\"), include.lowest = TRUE)\n\nall_data_transactions$`description length` &lt;- cut(all_data$`description length`, breaks = 3, labels = c(\"Bajo\", \"Medio\", \"Alto\"), include.lowest = TRUE)\n\nall_data_transactions$`#posts` &lt;- cut(all_data$`#posts`, breaks = 3, labels = c(\"Bajo\", \"Medio\", \"Alto\"), include.lowest = TRUE)\n\nall_data_transactions$`#followers` &lt;- cut(all_data$`#followers`, breaks = 3, labels = c(\"Bajo\", \"Medio\", \"Alto\"), include.lowest = TRUE)\n\nall_data_transactions$`#follows` &lt;- cut(all_data$`#follows`, breaks = 3, labels = c(\"Bajo\", \"Medio\", \"Alto\"), include.lowest = TRUE)\n\nUna vez se han discretizado las variables…\n\nfcInstagram &lt;- FormalContext$new(all_data_transactions)\n\nTras haber creado el objeto de la clase FormalContext para empezar a trabajar, es necesario antes dejarlo preparado para lo mismo. Para ello, es necesario aplicar escalas mediante scale.\n\nfcInstagram$scale(\"profile pic\",\"Nominal\")\nfcInstagram$scale(\"nums/length username\",\"Biordinal\")\nfcInstagram$scale(\"fullname words\",\"Biordinal\")\nfcInstagram$scale(\"nums/length fullname\",\"Biordinal\")\nfcInstagram$scale(\"name==username\",\"Nominal\")\nfcInstagram$scale(\"description length\",\"Biordinal\")\nfcInstagram$scale(\"external URL\",\"Nominal\")\nfcInstagram$scale(\"private\",\"Nominal\")\nfcInstagram$scale(\"#posts\",\"Biordinal\")\nfcInstagram$scale(\"#followers\",\"Biordinal\")\nfcInstagram$scale(\"#follows\",\"Biordinal\")\nfcInstagram$scale(\"fake\",\"Nominal\")\n\nPara comprobar que todos los atributos se han escalado de manera correcta, y que el proceso ha ido como se esperaba, podemos mostrar los atributos del objeto FCA de la siguiente manera:\n\nfcInstagram$attributes\n\n [1] \"profile pic = 0\"               \"profile pic = 1\"              \n [3] \"nums/length username &lt;= Alto\"  \"nums/length username &lt;= Bajo\" \n [5] \"nums/length username &lt;= Medio\" \"nums/length username &gt;= Alto\" \n [7] \"nums/length username &gt;= Bajo\"  \"nums/length username &gt;= Medio\"\n [9] \"fullname words &lt;= Alto\"        \"fullname words &lt;= Bajo\"       \n[11] \"fullname words &lt;= Medio\"       \"fullname words &gt;= Alto\"       \n[13] \"fullname words &gt;= Bajo\"        \"fullname words &gt;= Medio\"      \n[15] \"nums/length fullname &lt;= Alto\"  \"nums/length fullname &lt;= Bajo\" \n[17] \"nums/length fullname &lt;= Medio\" \"nums/length fullname &gt;= Alto\" \n[19] \"nums/length fullname &gt;= Bajo\"  \"nums/length fullname &gt;= Medio\"\n[21] \"name==username = 0\"            \"name==username = 1\"           \n[23] \"description length &lt;= Alto\"    \"description length &lt;= Bajo\"   \n[25] \"description length &lt;= Medio\"   \"description length &gt;= Alto\"   \n[27] \"description length &gt;= Bajo\"    \"description length &gt;= Medio\"  \n[29] \"external URL = 0\"              \"external URL = 1\"             \n[31] \"private = 0\"                   \"private = 1\"                  \n[33] \"#posts &lt;= Alto\"                \"#posts &lt;= Bajo\"               \n[35] \"#posts &lt;= Medio\"               \"#posts &gt;= Alto\"               \n[37] \"#posts &gt;= Bajo\"                \"#posts &gt;= Medio\"              \n[39] \"#followers &lt;= Alto\"            \"#followers &lt;= Bajo\"           \n[41] \"#followers &lt;= Medio\"           \"#followers &gt;= Alto\"           \n[43] \"#followers &gt;= Bajo\"            \"#followers &gt;= Medio\"          \n[45] \"#follows &lt;= Alto\"              \"#follows &lt;= Bajo\"             \n[47] \"#follows &lt;= Medio\"             \"#follows &gt;= Alto\"             \n[49] \"#follows &gt;= Bajo\"              \"#follows &gt;= Medio\"            \n[51] \"fake = 0\"                      \"fake = 1\"                     \n\n\nComo podemos ver en la salida, el haber aplicado unas discretizaciones iniciales aprovechadas de la sección anterior, además del escalado ha generado un total de 52 atributos en el objeto FormalContext. Esto, a la hora de generar los conceptos (que explicaremos más tarde con la función find_concepts) causaría una complejidad temporal de cómputo muy elevada, poco recomendable para aplicaciones cotidianas o de requerimiento temporal considerablemente rápido, como es nuestro caso. Por ello, vamos a tratar de arreglar esto…\n\nfcInstagram &lt;- FormalContext$new(all_data)\n\nUna posible solución para arreglar esto es calcular los quantiles para cada uno de los atributos, y aplicar un escalada por intervalos para dichos valores computados. De esta manera, la distribución y el número de atributos generados será mucho mejor. Se haría de la siguiente manera…\n\\[\nQ(p) = \\inf \\{x : F(x) \\geq p\\}\n\\] donde \\(Q(p)\\) es el cuantil por detrás de orden \\(p\\), \\(F(x)\\) es la función de distribución acumulativa e \\(inf\\) es el ínfimo, es decir, el valor minimo del conjunto, donde:\n\\[\nF(x) = P(X \\leq x)\n\\]\n\n#profile pic\nfcInstagram$scale(\"profile pic\",\"Nominal\")\n\n#nums/length username\npuntos_1 &lt;- round(quantile(unique(all_data$`nums/length username`),\n                  c(1/3, 2/3)),digits = 2)\nfcInstagram$scale(\"nums/length username\",\"Interval\",\n                  values = c(-Inf,puntos_1[1],puntos_1[2],Inf))\n\n#fullname words\npuntos_2 &lt;- round(quantile(unique(all_data$`fullname words`),\n                     c(1/2)), digits = 2)\nfcInstagram$scale(\"fullname words\",\"Interval\",\n                  values = c(-Inf,puntos_2[1],Inf))\n\n#nums/length fullname\npuntos_3 &lt;- round(quantile(unique(all_data$`nums/length fullname`),\n                  c(1/3, 2/3)), digits = 2)\nfcInstagram$scale(\"nums/length fullname\",\"Interval\",\n                  values = c(-Inf,puntos_3[1],puntos_3[2],Inf))\n\n#name==username\nfcInstagram$scale(\"name==username\",\"Nominal\")\n\n#description length\npuntos_4 &lt;- round(quantile(unique(all_data$`description length`),\n                  c(1/3, 2/3)), digits = 2)\nfcInstagram$scale(\"description length\",\"Interval\",\n                  values = c(-Inf,puntos_4[1],puntos_4[2],Inf))\n\n#external URL\nfcInstagram$scale(\"external URL\",\"Nominal\")\n\n#private\nfcInstagram$scale(\"private\",\"Nominal\")\n\n#posts\npuntos_5 &lt;- round(quantile(unique(all_data$`#posts`),\n                  c(1/3, 2/3)), digits = 2)\nfcInstagram$scale(\"#posts\",\"Interval\",\n                  values = c(-Inf,puntos_5[1],puntos_5[2],Inf))\n\n#followers\npuntos_6 &lt;- round(quantile(unique(all_data$`#followers`),\n                  c(1/3, 2/3)), digits = 2)\nfcInstagram$scale(\"#followers\",\"Interval\",\n                  values = c(-Inf,puntos_6[1],puntos_6[2],Inf))\n\n#follows\npuntos_7 &lt;- round(quantile(unique(all_data$`#follows`),\n                  c(1/3, 2/3)), digits = 2)\nfcInstagram$scale(\"#follows\",\"Interval\",\n                  values = c(-Inf,puntos_7[1],puntos_7[2],Inf))\n\n#fake\nfcInstagram$scale(\"fake\",\"Nominal\")\n\nUna vez hemos realizado todos los escalados de los diferentes atributos presentes en nuestro conjunto de datos, podemos probar a mostrar el numero de atributos presentes en el objeto FormalContext:\n\nlength(fcInstagram$attributes)\n\n[1] 30\n\n\nHemos logrado bajar de 52 atributos a 30. Puede que esta mejora nos permita poder calcular conceptos más tarde.\nAntes de nada, vamos a comenzar a investigar qué es capaz de hacer fcaR. En primer lugar, podemos definir las operaciones básicas: intent para calcular al conjunto de atributos que son compartidos por todos los objetos incluidos en ese concepto y extent para el conjunto de objetos que cumplen con todos los atributos especificados en el intento de ese concepto:\n\\[\nA \\uparrow \\hspace{1mm} := \\{m \\in M : (g,m) \\in I, \\forall g \\in A\\}\n\\]\n\\[\nB \\downarrow \\hspace{1mm} := \\{g \\in G : (g,m) \\in I, \\forall m \\in B\\}\n\\]\nUn ejemplo de ello podría ser…\n\n# Para calcuar {411,695}⬆\nset_objects &lt;- Set$new(fcInstagram$objects)\nset_objects$assign(\"411\" = 1, \"695\" = 1)\nfcInstagram$intent(set_objects)\n\n{profile pic = 0, nums/length username is (-Inf, 0.24], fullname words is (-Inf,\n  5], nums/length fullname is (-Inf, 0.23], name==username = 0, description\n  length is (-Inf, 37.67], external URL = 0, #posts is (-Inf, 81], fake = 1}\n\n\n\n# Para calcuar {private = 1,fake = 0}⬇\nset_attributes &lt;- Set$new(fcInstagram$attributes)\nset_attributes$assign(\"private = 1\" = 1, \"fake = 0\" = 1, \"#posts is (-Inf, 81]\" = 1)\nfcInstagram$extent(set_attributes)\n\n{3, 5, 22, 26, 27, 30, 32, 37, 39, 47, 48, 73, 75, 76, 78, 82, 92, 102, 104,\n  113, 114, 118, 121, 122, 125, 127, 129, 136, 143, 144, 151, 152, 153, 159,\n  162, 167, 168, 169, 171, 181, 182, 186, 187, 188, 193, 196, 199, 202, 206,\n  212, 216, 224, 225, 226, 238, 239, 240, 241, 243, 244, 245, 248, 250, 253,\n  254, 258, 263, 264, 267, 269, 272, 274, 276, 282, 283, 285, 288, 577, 578,\n  581, 582, 583, 584, 585, 586, 587, 589, 590, 592, 593, 597, 598, 599, 600,\n  602, 605, 610, 617, 621, 628, 630, 636}\n\n\nSe define también la operación closure, como la combinación de las dos anteriores ⬇⬆. El uso de la misma es el siguiente:\n\nset_attributes1 &lt;- Set$new(fcInstagram$attributes)\nset_attributes1$assign(\"fake = 1\" = 1)\nfcInstagram$closure(set_attributes1)\n\n{fullname words is (-Inf, 5], external URL = 0, fake = 1}\n\n\nComo se puede apreciar, la operación closure a priori parece que debería de volver al mismo atributo del cual partíamos, pero no es así. De hecho si lo pensamos, realmente lo que se hace internamente es ver que objetos del dataset comparten (en este caso) que son cuentas falsas, y luego ver de todos esos objetos que atributos comparten, por ello la operación no tiene por qué acabar como empezó.\nUna vez hemos visto las operaciones básicas de fcaR podemos pasar al plato fuerte. Se trata de los propios conceptos, que los calcularemos mediante find_concepts. Además, mediremos el tiempo de cómputo de la misma, mediante Sys.time…\n\ntiempoActual1 &lt;- Sys.time()\nfcInstagram$find_concepts()\ntiempoActual2 &lt;- Sys.time()\n\ntiempoActual2 - tiempoActual1\n\nTime difference of 3.393238 secs\n\nfcInstagram$concepts$size()\n\n[1] 10837\n\n\nAl ser un dataset con tantas filas, el número de conceptos que fcaR es realmente elevado.\n\nrandIndex &lt;- sample(1:fcInstagram$concepts$size(), 1)\nfcInstagram$concepts[randIndex]\n\nA set of 1 concepts:\n1: ({78, 81, 122, 134, 165, 167, 168, 171, 187, 202, 229, 231, 244, 250, 289, 293, 310, 322, 325, 328, 359, 378, 380, 385, 403, 428, 436, 447, 461, 467, 491, 523, 527, 541, 542, 547, 554, 563, 574, 576, 589, 593, 597, 665, 668}, {fullname words is (-Inf, 5], nums/length fullname is (-Inf, 0.23], name==username = 0, external URL = 0, #followers is (-Inf, 206.67], #follows is (229.67, 602]})\n\n\nAl igual que ocurría en reglas de asociación, es posible extraer subconjuntos de los conceptos en fcaR que presenten ciertas cualidad o caracteristicas a filtrar. Para ello, podríamos primero visualizar cuáles son los atributos públicos de los cuales dispone el ConceptSet.\n\nstr(fcInstagram$concepts)\n\nClasses 'ConceptLattice', 'ConceptSet', 'R6' &lt;ConceptLattice&gt;\n  Inherits from: &lt;ConceptSet&gt;\n  Public:\n    [: function (indices) \n    bottom: function () \n    clone: function (deep = FALSE) \n    decompose: function (C) \n    extents: function () \n    infimum: function (...) \n    initialize: function (extents, intents, objects, attributes, I = NULL) \n    intents: function () \n    is_empty: function () \n    join_irreducibles: function () \n    lower_neighbours: function (C) \n    meet_irreducibles: function () \n    plot: function (object_names = TRUE, to_latex = FALSE, ...) \n    print: function () \n    size: function () \n    sub: function (index) \n    subconcepts: function (C) \n    sublattice: function (...) \n    superconcepts: function (C) \n    support: function () \n    supremum: function (...) \n    to_latex: function (print = TRUE, ncols = 1, numbered = TRUE, align = TRUE) \n    to_list: function () \n    top: function () \n    upper_neighbours: function (C) \n  Private:\n    attributes: profile pic = 0 profile pic = 1 nums/length username is  ...\n    can_plot: TRUE\n    concept_list_to_indices: function (concept_list) \n    concept_support: NULL\n    I: dgCMatrix\n    objects: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 ...\n    pr_extents: dgCMatrix\n    pr_intents: dgCMatrix\n    reduced_matrix: NULL\n    subconcept_matrix: NULL\n    to_indices: function (...)  \n\n\nVemos, por ejemplo, que disponemos de un atributo llamado “support”, que corresponde a los soportes de los distintos conceptos. Si quisieramos filtrar por ellos…\n\nidxFilteredConcepts &lt;- which(fcInstagram$concepts$support() &gt; 0.85)\nlength(idxFilteredConcepts)\n\n[1] 11\n\n\nSe puede apreciar que de los 10837 conceptos que habíamos computado en primera instancia, solo 11 de ellos disponen de un soporte superior a 0,85.\nUsando la función sublattice de ConceptSet podemos encontrar un subconjunto del conjunto de conceptos. Un sublattice es un subconjunto de conceptos que también forma un lattice completo, lo que significa que cumple con las propiedades de un lattice, como la existencia de un supremo y un ínfimo para cualquier par de elementos\n\n# Build the sublattice\nsublattice &lt;- fcInstagram$concepts$sublattice(idxFilteredConcepts)\nsublattice\n\nA set of 16 concepts:\n1: ({1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696}, {})\n2: ({1, 2, 3, 4, 5, 7, 8, 9, 11, 16, 17, 18, 21, 23, 24, 25, 27, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 52, 55, 57, 58, 59, 60, 61, 63, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 139, 140, 142, 143, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 167, 168, 169, 170, 171, 175, 176, 178, 179, 180, 181, 182, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 201, 202, 203, 204, 206, 207, 209, 211, 212, 214, 216, 217, 218, 219, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 239, 240, 241, 242, 244, 245, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 604, 605, 607, 610, 611, 612, 613, 617, 620, 621, 623, 624, 625, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696}, {external URL = 0})\n3: ({1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 348, 349, 350, 352, 353, 354, 355, 356, 357, 358, 359, 361, 362, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 435, 436, 437, 438, 439, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 456, 457, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 551, 553, 554, 555, 556, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642, 643, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696}, {name==username = 0})\n4: ({1, 2, 3, 4, 5, 7, 8, 9, 11, 16, 17, 18, 21, 23, 24, 25, 27, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 52, 55, 57, 58, 59, 60, 61, 63, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 139, 140, 142, 143, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 167, 168, 169, 170, 171, 175, 176, 178, 179, 180, 181, 182, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 201, 202, 203, 204, 206, 207, 209, 211, 212, 214, 216, 217, 218, 219, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 239, 240, 241, 242, 244, 245, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 348, 349, 350, 352, 353, 354, 355, 356, 357, 358, 359, 361, 362, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 435, 436, 437, 438, 439, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 456, 457, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 551, 553, 554, 555, 556, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 604, 605, 607, 610, 611, 612, 613, 617, 620, 621, 623, 624, 625, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642, 643, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696}, {name==username = 0, external URL = 0})\n5: ({1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 325, 327, 328, 329, 331, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 348, 350, 351, 352, 353, 354, 355, 356, 357, 359, 360, 361, 362, 364, 365, 366, 367, 368, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 430, 431, 432, 433, 435, 436, 437, 438, 439, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 453, 454, 455, 456, 457, 458, 459, 460, 461, 463, 464, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 516, 519, 521, 522, 523, 525, 526, 527, 529, 530, 531, 532, 534, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 549, 550, 551, 553, 554, 559, 562, 563, 564, 565, 567, 568, 569, 570, 571, 574, 575, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 647, 648, 651, 652, 653, 655, 656, 659, 660, 661, 663, 664, 665, 666, 667, 668, 669, 670, 671, 673, 674, 677, 678, 679, 680, 681, 683, 685, 686, 687, 689, 691, 692, 693, 694, 695, 696}, {nums/length fullname is (-Inf, 0.23]})\n6: ({1, 2, 3, 4, 5, 7, 8, 9, 11, 16, 17, 18, 21, 23, 24, 25, 27, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 52, 55, 57, 58, 59, 60, 61, 63, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 139, 140, 142, 143, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 167, 168, 169, 170, 171, 175, 176, 178, 179, 180, 181, 182, 186, 187, 188, 189, 191, 192, 193, 196, 197, 198, 201, 202, 203, 204, 206, 207, 209, 211, 212, 214, 216, 217, 218, 219, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 239, 240, 241, 242, 244, 245, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 325, 327, 328, 329, 331, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 348, 350, 351, 352, 353, 354, 355, 356, 357, 359, 360, 361, 362, 364, 365, 366, 367, 368, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 430, 431, 432, 433, 435, 436, 437, 438, 439, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 453, 454, 455, 456, 457, 458, 459, 460, 461, 463, 464, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 516, 519, 521, 522, 523, 525, 526, 527, 529, 530, 531, 532, 534, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 549, 550, 551, 553, 554, 559, 562, 563, 564, 565, 567, 568, 569, 570, 571, 574, 575, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 604, 605, 607, 610, 611, 612, 617, 620, 621, 623, 624, 625, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 647, 648, 651, 652, 653, 655, 656, 659, 660, 661, 663, 664, 665, 666, 667, 668, 669, 670, 671, 673, 674, 677, 678, 679, 680, 681, 683, 685, 686, 687, 689, 691, 692, 693, 694, 695, 696}, {nums/length fullname is (-Inf, 0.23], external URL = 0})\n7: ({1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 325, 327, 328, 329, 331, 333, 334, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 348, 350, 352, 353, 354, 355, 356, 357, 359, 361, 362, 364, 365, 366, 367, 368, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 430, 431, 432, 433, 435, 436, 437, 438, 439, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 453, 454, 456, 457, 459, 460, 461, 463, 464, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 514, 516, 519, 521, 522, 523, 525, 526, 527, 529, 530, 531, 532, 534, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 551, 553, 554, 559, 562, 563, 564, 565, 567, 568, 569, 570, 571, 574, 575, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642, 643, 645, 647, 648, 651, 652, 653, 655, 656, 659, 660, 661, 663, 664, 665, 666, 667, 668, 669, 670, 671, 673, 674, 677, 678, 679, 680, 681, 683, 685, 686, 687, 689, 691, 692, 693, 694, 695, 696}, {nums/length fullname is (-Inf, 0.23], name==username = 0})\n8: ({1, 2, 3, 4, 5, 7, 8, 9, 11, 16, 17, 18, 21, 23, 24, 25, 27, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 52, 55, 57, 58, 59, 60, 61, 63, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 139, 140, 142, 143, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 167, 168, 169, 170, 171, 175, 176, 178, 179, 180, 181, 182, 186, 187, 188, 189, 191, 192, 193, 196, 197, 198, 201, 202, 203, 204, 206, 207, 209, 211, 212, 214, 216, 217, 218, 219, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 239, 240, 241, 242, 244, 245, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 325, 327, 328, 329, 331, 333, 334, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 348, 350, 352, 353, 354, 355, 356, 357, 359, 361, 362, 364, 365, 366, 367, 368, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 430, 431, 432, 433, 435, 436, 437, 438, 439, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 453, 454, 456, 457, 459, 460, 461, 463, 464, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 514, 516, 519, 521, 522, 523, 525, 526, 527, 529, 530, 531, 532, 534, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 551, 553, 554, 559, 562, 563, 564, 565, 567, 568, 569, 570, 571, 574, 575, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 604, 605, 607, 610, 611, 612, 617, 620, 621, 623, 624, 625, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642, 643, 645, 647, 648, 651, 652, 653, 655, 656, 659, 660, 661, 663, 664, 665, 666, 667, 668, 669, 670, 671, 673, 674, 677, 678, 679, 680, 681, 683, 685, 686, 687, 689, 691, 692, 693, 694, 695, 696}, {nums/length fullname is (-Inf, 0.23], name==username = 0, external URL = 0})\n9: ({1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696}, {fullname words is (-Inf, 5]})\n10: ({1, 2, 3, 4, 5, 7, 8, 9, 11, 16, 17, 18, 21, 23, 24, 25, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 52, 55, 57, 58, 59, 60, 61, 63, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 139, 140, 142, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 167, 168, 169, 170, 171, 175, 176, 178, 179, 180, 181, 182, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 201, 202, 203, 204, 206, 207, 209, 211, 212, 214, 216, 217, 218, 219, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 239, 240, 241, 242, 244, 245, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 604, 605, 607, 610, 611, 612, 613, 617, 620, 621, 623, 624, 625, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696}, {fullname words is (-Inf, 5], external URL = 0})\n11: ({1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 348, 349, 350, 352, 353, 354, 355, 356, 357, 358, 359, 361, 362, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 435, 436, 437, 438, 439, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 456, 457, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 551, 553, 554, 555, 556, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 641, 642, 643, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696}, {fullname words is (-Inf, 5], name==username = 0})\n12: ({1, 2, 3, 4, 5, 7, 8, 9, 11, 16, 17, 18, 21, 23, 24, 25, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 52, 55, 57, 58, 59, 60, 61, 63, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 139, 140, 142, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 167, 168, 169, 170, 171, 175, 176, 178, 179, 180, 181, 182, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 201, 202, 203, 204, 206, 207, 209, 211, 212, 214, 216, 217, 218, 219, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 239, 240, 241, 242, 244, 245, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 348, 349, 350, 352, 353, 354, 355, 356, 357, 358, 359, 361, 362, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 435, 436, 437, 438, 439, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 456, 457, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 551, 553, 554, 555, 556, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 604, 605, 607, 610, 611, 612, 613, 617, 620, 621, 623, 624, 625, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 641, 642, 643, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696}, {fullname words is (-Inf, 5], name==username = 0, external URL = 0})\n13: ({1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 325, 327, 328, 329, 331, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 348, 350, 351, 352, 353, 354, 355, 356, 357, 359, 360, 361, 362, 364, 365, 366, 367, 368, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 430, 431, 432, 433, 435, 436, 437, 438, 439, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 453, 454, 455, 456, 457, 458, 459, 460, 461, 463, 464, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 516, 519, 521, 522, 523, 525, 526, 527, 529, 530, 531, 532, 534, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 549, 550, 551, 553, 554, 559, 562, 563, 564, 565, 567, 568, 569, 570, 571, 574, 575, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 647, 648, 651, 652, 653, 655, 656, 659, 660, 661, 663, 664, 665, 666, 667, 668, 669, 670, 671, 673, 674, 677, 678, 679, 680, 681, 683, 685, 686, 687, 689, 691, 692, 693, 694, 695, 696}, {fullname words is (-Inf, 5], nums/length fullname is (-Inf, 0.23]})\n14: ({1, 2, 3, 4, 5, 7, 8, 9, 11, 16, 17, 18, 21, 23, 24, 25, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 52, 55, 57, 58, 59, 60, 61, 63, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 139, 140, 142, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 167, 168, 169, 170, 171, 175, 176, 178, 179, 180, 181, 182, 186, 187, 188, 189, 191, 192, 193, 196, 197, 198, 201, 202, 203, 204, 206, 207, 209, 211, 212, 214, 216, 217, 218, 219, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 239, 240, 241, 242, 244, 245, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 325, 327, 328, 329, 331, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 348, 350, 351, 352, 353, 354, 355, 356, 357, 359, 360, 361, 362, 364, 365, 366, 367, 368, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 430, 431, 432, 433, 435, 436, 437, 438, 439, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 453, 454, 455, 456, 457, 458, 459, 460, 461, 463, 464, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 516, 519, 521, 522, 523, 525, 526, 527, 529, 530, 531, 532, 534, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 549, 550, 551, 553, 554, 559, 562, 563, 564, 565, 567, 568, 569, 570, 571, 574, 575, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 604, 605, 607, 610, 611, 612, 617, 620, 621, 623, 624, 625, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 647, 648, 651, 652, 653, 655, 656, 659, 660, 661, 663, 664, 665, 666, 667, 668, 669, 670, 671, 673, 674, 677, 678, 679, 680, 681, 683, 685, 686, 687, 689, 691, 692, 693, 694, 695, 696}, {fullname words is (-Inf, 5], nums/length fullname is (-Inf, 0.23], external URL = 0})\n15: ({1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 325, 327, 328, 329, 331, 333, 334, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 348, 350, 352, 353, 354, 355, 356, 357, 359, 361, 362, 364, 365, 366, 367, 368, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 430, 431, 432, 433, 435, 436, 437, 438, 439, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 453, 454, 456, 457, 459, 460, 461, 463, 464, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 514, 516, 519, 521, 522, 523, 525, 526, 527, 529, 530, 531, 532, 534, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 551, 553, 554, 559, 562, 563, 564, 565, 567, 568, 569, 570, 571, 574, 575, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 641, 642, 643, 645, 647, 648, 651, 652, 653, 655, 656, 659, 660, 661, 663, 664, 665, 666, 667, 668, 669, 670, 671, 673, 674, 677, 678, 679, 680, 681, 683, 685, 686, 687, 689, 691, 692, 693, 694, 695, 696}, {fullname words is (-Inf, 5], nums/length fullname is (-Inf, 0.23], name==username = 0})\n16: ({1, 2, 3, 4, 5, 7, 8, 9, 11, 16, 17, 18, 21, 23, 24, 25, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 52, 55, 57, 58, 59, 60, 61, 63, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 139, 140, 142, 144, 145, 146, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 167, 168, 169, 170, 171, 175, 176, 178, 179, 180, 181, 182, 186, 187, 188, 189, 191, 192, 193, 196, 197, 198, 201, 202, 203, 204, 206, 207, 209, 211, 212, 214, 216, 217, 218, 219, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 237, 238, 239, 240, 241, 242, 244, 245, 247, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 325, 327, 328, 329, 331, 333, 334, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 348, 350, 352, 353, 354, 355, 356, 357, 359, 361, 362, 364, 365, 366, 367, 368, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 383, 384, 385, 386, 387, 388, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 430, 431, 432, 433, 435, 436, 437, 438, 439, 441, 443, 444, 445, 446, 447, 448, 449, 450, 451, 453, 454, 456, 457, 459, 460, 461, 463, 464, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 514, 516, 519, 521, 522, 523, 525, 526, 527, 529, 530, 531, 532, 534, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 550, 551, 553, 554, 559, 562, 563, 564, 565, 567, 568, 569, 570, 571, 574, 575, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 604, 605, 607, 610, 611, 612, 617, 620, 621, 623, 624, 625, 627, 628, 629, 630, 631, 633, 634, 635, 636, 637, 638, 639, 641, 642, 643, 645, 647, 648, 651, 652, 653, 655, 656, 659, 660, 661, 663, 664, 665, 666, 667, 668, 669, 670, 671, 673, 674, 677, 678, 679, 680, 681, 683, 685, 686, 687, 689, 691, 692, 693, 694, 695, 696}, {fullname words is (-Inf, 5], nums/length fullname is (-Inf, 0.23], name==username = 0, external URL = 0})\n\nsublattice$plot()\n\n\n\n\nHemos usado además plot() de ConceptSet para mostrar el lattice. Genera un diagrama visual del conjunto de conceptos representando el lattice. Este diagrama muestra las relaciones de inclusión entre los conceptos, donde cada nodo del gráfico representa un concepto y las líneas conectan los mismos que están relacionados por la inclusión.\nPasemos ahora a otra de las cualidades importantes de fcaR. Es capaz de encontrar implicaciones (de manera similar a lo que hacíamos con apriori en la sección anterior del book). Para hacer uso de esta funcionalidad, se llama a la función find_implications.\n\nfcInstagram$find_implications()\n\nLa manera de ver el número de implicaciones generadas o calculadas, es un poco distinta a como ocurría con los conceptos:\n\n# Opcion 1\nfcInstagram$implications$cardinality()\n\n[1] 851\n\n# Opcion 2\nnrow(fcInstagram$implications$size())\n\n[1] 851\n\n\n\nfcInstagram$implications[1:5]\n\nImplication set with 5 implications.\nRule 1: {fake = 1} -&gt; {fullname words is (-Inf, 5], external URL = 0}\nRule 2: {#follows is (229.67, 602], fake = 0} -&gt; {name==username = 0}\nRule 3: {#follows is (229.67, 602], #follows is (602, Inf]} -&gt; {profile pic = 0,\n  profile pic = 1, nums/length username is (-Inf, 0.24], nums/length username is\n  (0.24, 0.5], nums/length username is (0.5, Inf], fullname words is (-Inf, 5],\n  fullname words is (5, Inf], nums/length fullname is (-Inf, 0.23], nums/length\n  fullname is (0.23, 0.39], nums/length fullname is (0.39, Inf], name==username\n  = 0, name==username = 1, description length is (-Inf, 37.67], description\n  length is (37.67, 82.67], description length is (82.67, Inf], external URL =\n  0, external URL = 1, private = 0, private = 1, #posts is (-Inf, 81], #posts is\n  (81, 251], #posts is (251, Inf], #followers is (-Inf, 206.67], #followers is\n  (206.67, 803], #followers is (803, Inf], #follows is (-Inf, 229.67], fake = 0,\n  fake = 1}\nRule 4: {#follows is (-Inf, 229.67], fake = 0} -&gt; {profile pic = 1}\nRule 5: {#follows is (-Inf, 229.67], #follows is (602, Inf]} -&gt; {profile pic\n  = 0, profile pic = 1, nums/length username is (-Inf, 0.24], nums/length\n  username is (0.24, 0.5], nums/length username is (0.5, Inf], fullname words is\n  (-Inf, 5], fullname words is (5, Inf], nums/length fullname is (-Inf, 0.23],\n  nums/length fullname is (0.23, 0.39], nums/length fullname is (0.39, Inf],\n  name==username = 0, name==username = 1, description length is (-Inf, 37.67],\n  description length is (37.67, 82.67], description length is (82.67, Inf],\n  external URL = 0, external URL = 1, private = 0, private = 1, #posts is (-Inf,\n  81], #posts is (81, 251], #posts is (251, Inf], #followers is (-Inf, 206.67],\n  #followers is (206.67, 803], #followers is (803, Inf], #follows is (229.67,\n  602], fake = 0, fake = 1}\n\n\nSi quisieramos ver cuál es la media de número de atributos en las partes izquierda y derecha de nuestras reglas, podríamos usar colMeans…\n\nsizes &lt;- fcInstagram$implications$size()\ncolMeans(sizes)\n\n     LHS      RHS \n6.905993 2.340776 \n\n\nEsto nos da una idea de la estructura general (en su mayoría) de las reglas de las cuales disponemos, siendo la media de la parte izquierda de 7 elementos/atributos frente a 2 aprox. en la parte derecha.\nSi quisieramos ver de manera más “elegante” y visual algunas de las reglas, ImplicationSet también dispone de un metodo to_latex.\n\nfcInstagram$implications[1:3]$to_latex()\n\nNote: You must include the following commands in you LaTeX document:\n\\usepackage{amsmath}\\newcommand{\\el}[2]{\\ensuremath{^{#2\\!\\!}/{#1}}}\n\n\n\\begin{longtable*}{rrcl}\n1: &\\left\\{\\mathrm{fake = 1}\\right\\}&\\ensuremath{\\Rightarrow}&\\left\\{\\mathrm{fullname words is (-Inf, 5]}, \\mathrm{external URL = 0}\\right\\}\\\\\n2: &\\left\\{\\mathrm{\\#follows is (229.67, 602]}, \\mathrm{fake = 0}\\right\\}&\\ensuremath{\\Rightarrow}&\\left\\{\\mathrm{name==username = 0}\\right\\}\\\\\n3: &\\left\\{\\mathrm{\\#follows is (229.67, 602]}, \\mathrm{\\#follows is (602, Inf]}\\right\\}&\\ensuremath{\\Rightarrow}&\\left\\{\\mathrm{profile pic = 0}, \\mathrm{profile pic = 1}, \\mathrm{nums/length username is (-Inf, 0.24]}, \\mathrm{nums/length username is (0.24, 0.5]}, \\mathrm{nums/length username is (0.5, Inf]}, \\mathrm{fullname words is (-Inf, 5]}, \\mathrm{fullname words is (5, Inf]}, \\mathrm{nums/length fullname is (-Inf, 0.23]}, \\mathrm{nums/length fullname is (0.23, 0.39]}, \\mathrm{nums/length fullname is (0.39, Inf]}, \\mathrm{name==username = 0}, \\mathrm{name==username = 1}, \\mathrm{description length is (-Inf, 37.67]}, \\mathrm{description length is (37.67, 82.67]}, \\mathrm{description length is (82.67, Inf]}, \\mathrm{external URL = 0}, \\mathrm{external URL = 1}, \\mathrm{private = 0}, \\mathrm{private = 1}, \\mathrm{\\#posts is (-Inf, 81]}, \\mathrm{\\#posts is (81, 251]}, \\mathrm{\\#posts is (251, Inf]}, \\mathrm{\\#followers is (-Inf, 206.67]}, \\mathrm{\\#followers is (206.67, 803]}, \\mathrm{\\#followers is (803, Inf]}, \\mathrm{\\#follows is (-Inf, 229.67]}, \\mathrm{fake = 0}, \\mathrm{fake = 1}\\right\\}\\\\\n\\end{longtable*}\n\n\nEn el caso en el que quisieramos reducir los tamaños de las reglas (lo cual suele ser beneficioso a modo de preprocessing), podriamos hacer lo siguiente para lograrlo:\n\nequivalencesRegistry$get_entry_names()\n\n[1] \"Composition\"          \"Generalization\"       \"Reduction\"           \n[4] \"Simplification\"       \"Right Simplification\" \"Reorder\"             \n\nfcInstagram$implications$apply_rules(rules = c(\"composition\",\n                                        \"generalization\",\n                                        \"simplification\"))\n\nProcessing batch\n\n\n--&gt; Composition: from 851 to 851.\n\n\n--&gt; Generalization: from 851 to 851.\n\n\n--&gt; Simplification: from 851 to 851.\n\n\n\nsizes &lt;- fcInstagram$implications$size()\ncolMeans(sizes)\n\n     LHS      RHS \n3.392479 2.340776 \n\n\nSe puede apreciar como hemos reducido en 2 el tamaño de las partes izquierdas del conjunto de reglas. Como último toque sobre conceptos y fcaR podríamos incluir 2 métodos distintos de extracción de conocimiento a partir de reglas aprendidas a lo largo de la asignatura.\n\n# METODO 1 PARA EXTRAER INFORMACION\ncuentasFake &lt;- fcInstagram$implications$filter(rhs=\"fake = 1\",\n                                               not_rhs = \"fake = 0\")\n\ncuentasFake$cardinality()\n\n[1] 44\n\npartesIzquierda &lt;- cuentasFake$get_LHS_matrix()\n\n# Nos quedamos con las partes izquierdas de dichas reglas\nnombres_atributos_lista &lt;- apply(partesIzquierda, 2, function(x) names(x[x == 1]))\n\n# Cada elemento de 'nombre_atributos_lista' es a su vez una lista\nlength(nombres_atributos_lista)\n\n[1] 44\n\n# En nombres_atributos_lista ya se pueden ver los atributos que mas se repiten y asi sacar conclusiones. Igualmente si quisieramos verlo de manera formal con table se puede ver la frecuencia de cada item.\n\natribOrdFreq &lt;- sort(table(unlist(nombres_atributos_lista)),\n                     decreasing = TRUE)\n\nknitr::kable(atribOrdFreq,\n             col.names = c(\"Atributo\",\"Frecuencia/Repeticiones\"))\n\n\n\n\nAtributo\nFrecuencia/Repeticiones\n\n\n\n\nnums/length username is (0.24, 0.5]\n13\n\n\nprofile pic = 0\n11\n\n\n#followers is (-Inf, 206.67]\n10\n\n\ndescription length is (-Inf, 37.67]\n9\n\n\n#follows is (602, Inf]\n8\n\n\nprivate = 1\n8\n\n\nname==username = 1\n7\n\n\nnums/length fullname is (0.23, 0.39]\n7\n\n\nprivate = 0\n7\n\n\n#posts is (-Inf, 81]\n6\n\n\n#followers is (206.67, 803]\n4\n\n\n#follows is (-Inf, 229.67]\n4\n\n\n#follows is (229.67, 602]\n4\n\n\n#posts is (251, Inf]\n4\n\n\n#posts is (81, 251]\n4\n\n\nexternal URL = 0\n4\n\n\nname==username = 0\n4\n\n\n#followers is (803, Inf]\n3\n\n\ndescription length is (82.67, Inf]\n3\n\n\nnums/length username is (-Inf, 0.24]\n3\n\n\ndescription length is (37.67, 82.67]\n2\n\n\nexternal URL = 1\n1\n\n\nfullname words is (-Inf, 5]\n1\n\n\nfullname words is (5, Inf]\n1\n\n\nnums/length fullname is (-Inf, 0.23]\n1\n\n\nnums/length fullname is (0.39, Inf]\n1\n\n\nnums/length username is (0.5, Inf]\n1\n\n\n\n\n\nEsto nos da una idea de los atributos que más se repiten en reglas que nos llevan de un conjunto de atributos \\(X\\) hasta otro conjunto que al menos contiene \\(fake = 1\\), que es el atributo inferencia o a modelar. Se aprecia que “nums/length username is (0.24, 0.5]”, “profile pic = 0”, “#followers is (-Inf, 206.67]” y “description length is (-Inf, 37.67]” son los atributos que más aparecen en dichas reglas, y que por tanto son los que más decantan a la hora de decidir si la cuenta de Instagram en cuestión es fake o no.\n\n# METODO 2 PARA EXTRAER INFORMACION (mediante aRules)\nlibrary(arules)\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following object is masked from 'package:fcaR':\n\n    %&%\n\n\n\nAttaching package: 'arules'\n\n\nThe following objects are masked from 'package:base':\n\n    abbreviate, write\n\nreglas &lt;- fcInstagram$implications$to_arules()\n\nreglas &lt;- subset(reglas, rhs %in% \"fake = 1\")\n\nlength(reglas)\n\n[1] 61\n\nparteIzquierda &lt;- lhs(reglas)@data\n\nnombres_atributos_lista &lt;- apply(parteIzquierda, 2, function(x) reglas@lhs@itemInfo$labels[x])\n\n# En nombres_atributos_lista ya se pueden ver los atributos que mas se repiten y asi sacar conclusiones. Igualmente si quisieramos verlo de manera formal con table se puede ver la frecuencia de cada item.\n\natribOrdFreq &lt;- sort(table(unlist(nombres_atributos_lista)),\n                     decreasing = TRUE)\n\nknitr::kable(atribOrdFreq,\n             col.names = c(\"Atributo\",\"Frecuencia/Repeticiones\"))\n\n\n\n\nAtributo\nFrecuencia/Repeticiones\n\n\n\n\nnums/length username is (0.24, 0.5]\n14\n\n\n#followers is (-Inf, 206.67]\n12\n\n\nprofile pic = 0\n12\n\n\ndescription length is (-Inf, 37.67]\n11\n\n\n#follows is (602, Inf]\n10\n\n\nprivate = 1\n9\n\n\n#posts is (-Inf, 81]\n8\n\n\nname==username = 1\n8\n\n\nnums/length fullname is (0.23, 0.39]\n8\n\n\nprivate = 0\n8\n\n\n#followers is (206.67, 803]\n6\n\n\n#follows is (-Inf, 229.67]\n6\n\n\n#follows is (229.67, 602]\n6\n\n\n#posts is (251, Inf]\n6\n\n\n#posts is (81, 251]\n6\n\n\n#followers is (803, Inf]\n5\n\n\ndescription length is (82.67, Inf]\n5\n\n\nname==username = 0\n5\n\n\ndescription length is (37.67, 82.67]\n4\n\n\nexternal URL = 0\n4\n\n\nnums/length username is (-Inf, 0.24]\n4\n\n\nnums/length fullname is (-Inf, 0.23]\n2\n\n\nprofile pic = 1\n2\n\n\nexternal URL = 1\n1\n\n\nfullname words is (-Inf, 5]\n1\n\n\nfullname words is (5, Inf]\n1\n\n\nnums/length fullname is (0.39, Inf]\n1\n\n\nnums/length username is (0.5, Inf]\n1\n\n\n\n\n\nComo era lógico pensar, y como se ha mencionado, ambos métodos son relativamente equivalente en cuanto a funcionalidad, y es por ello por lo que el conocimiento que se extrae en ambos es el mismo.\nConsidero que con esto concluimos nuestra inmersión en el Análisis de Conceptos Formales (FCA), una potente disciplina que nos ha proporcionado una nueva perspectiva para entender la estructura de nuestros datos y descubrir patrones ocultos mediante la representación de conceptos y la exploración de implicaciones. Ahora, no sumergiremos en el mundo de los modelos de regresión, donde se verá cómo predecir y modelar variables de interés a partir de datos históricos y cómo utilizar estas predicciones para tomar decisiones informadas y resolver problemas del mundo real."
  },
  {
    "objectID": "regresion.html",
    "href": "regresion.html",
    "title": "5  Regresión",
    "section": "",
    "text": "Llega la hora de meternos de lleno en el mundo de los modelos de regresión. Se trata de un campos del análisis de datos realmente valioso e interesante ya que: nos permite modelar y entender las relaciones entre variables (lo que es fundamental para comprender cómo ciertos factores afectan a otros en un sistema dado), podemos predecir valores futuros basados en datos históricos, La regresión nos proporciona herramientas para evaluar la calidad y validez de nuestros modelos, estos son de diferentes naturalezas y muy versátiles, …\n\n  \n\nEl propósito final, por tanto, será encontrar modelos que dadas una serie de variables asociadas a un dataset, se ajusten a la nube de puntos generadas por las mismas, y que por tanto permita evaluar en un futuro datos que no han sido usados para generar el modelo en cuestión.\n\nlibrary(readr)\ntrain &lt;- read_csv(\"datasets/train.csv\")\n\nRows: 576 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntest &lt;- read_csv(\"datasets/test.csv\")\n\nRows: 120 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nall_data &lt;- rbind(train, test)\n\nEn primer lugar, para ver cuales pueden ser pares de variables interesantes de cara a representar, podemos usar pairs\n\npairs(all_data[colnames(all_data)])\n\n\n\nknitr::kable(cor(all_data))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprofile pic\nnums/length username\nfullname words\nnums/length fullname\nname==username\ndescription length\nexternal URL\nprivate\n#posts\n#followers\n#follows\nfake\n\n\n\n\nprofile pic\n1.0000000\n-0.3206651\n0.2198022\n-0.1113861\n-0.1325460\n0.3569033\n0.2280166\n0.1525347\n0.1695865\n0.0597795\n0.1581316\n-0.6245477\n\n\nnums/length username\n-0.3206651\n1.0000000\n-0.2362528\n0.4680883\n0.0608612\n-0.3172081\n-0.2331335\n-0.1043411\n-0.1611659\n-0.0635941\n-0.1667347\n0.5703625\n\n\nfullname words\n0.2198022\n-0.2362528\n1.0000000\n-0.1022177\n-0.0853250\n0.2751279\n0.2038937\n-0.0587288\n0.0867783\n0.0391406\n0.0621989\n-0.3004846\n\n\nnums/length fullname\n-0.1113861\n0.4680883\n-0.1022177\n1.0000000\n0.2600738\n-0.1193185\n-0.0934336\n-0.0750208\n-0.0625152\n-0.0275424\n-0.0526415\n0.2509043\n\n\nname==username\n-0.1325460\n0.0608612\n-0.0853250\n0.2600738\n1.0000000\n-0.0457051\n-0.0447284\n0.0282962\n-0.0504453\n-0.0180985\n-0.0071267\n0.1621392\n\n\ndescription length\n0.3569033\n-0.3172081\n0.2751279\n-0.1193185\n-0.0457051\n1.0000000\n0.4897756\n-0.0313382\n0.1850584\n0.0323332\n0.2243101\n-0.4788901\n\n\nexternal URL\n0.2280166\n-0.2331335\n0.2038937\n-0.0934336\n-0.0447284\n0.4897756\n1.0000000\n-0.1517716\n0.1988325\n0.0533685\n0.1304888\n-0.3578252\n\n\nprivate\n0.1525347\n-0.1043411\n-0.0587288\n-0.0750208\n0.0282962\n-0.0313382\n-0.1517716\n1.0000000\n-0.0717481\n-0.0715365\n-0.0620013\n-0.1339719\n\n\n#posts\n0.1695865\n-0.1611659\n0.0867783\n-0.0625152\n-0.0504453\n0.1850584\n0.1988325\n-0.0717481\n1.0000000\n0.3436164\n0.1141541\n-0.2506252\n\n\n#followers\n0.0597795\n-0.0635941\n0.0391406\n-0.0275424\n-0.0180985\n0.0323332\n0.0533685\n-0.0715365\n0.3436164\n1.0000000\n0.0205692\n-0.0938015\n\n\n#follows\n0.1581316\n-0.1667347\n0.0621989\n-0.0526415\n-0.0071267\n0.2243101\n0.1304888\n-0.0620013\n0.1141541\n0.0205692\n1.0000000\n-0.1542582\n\n\nfake\n-0.6245477\n0.5703625\n-0.3004846\n0.2509043\n0.1621392\n-0.4788901\n-0.3578252\n-0.1339719\n-0.2506252\n-0.0938015\n-0.1542582\n1.0000000\n\n\n\n\nmaximoCor &lt;- max(cor(all_data)[cor(all_data) != 1])\n\nwhich(cor(all_data) == maximoCor, arr.ind = TRUE)\n\n                     row col\nfake                  12   2\nnums/length username   2  12\n\n\nEl problema es que obtenemos que fake es la mejor opción de elección de atributos y sabemos que dicha variable es binaria, por lo que no se trataría de un modelo de regresión, sino de clasificación. Como este problema lo vamos a arrastrar durante esta sección, considero que una buena elección puede ser quitarnos temporalmente las variables binarias…\n\nbinary_vars &lt;- sapply(all_data, function(x) length(unique(x)) == 2)\n\nall_data &lt;- all_data[,!binary_vars]\n\nknitr::kable(cor(all_data))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnums/length username\nfullname words\nnums/length fullname\ndescription length\n#posts\n#followers\n#follows\n\n\n\n\nnums/length username\n1.0000000\n-0.2362528\n0.4680883\n-0.3172081\n-0.1611659\n-0.0635941\n-0.1667347\n\n\nfullname words\n-0.2362528\n1.0000000\n-0.1022177\n0.2751279\n0.0867783\n0.0391406\n0.0621989\n\n\nnums/length fullname\n0.4680883\n-0.1022177\n1.0000000\n-0.1193185\n-0.0625152\n-0.0275424\n-0.0526415\n\n\ndescription length\n-0.3172081\n0.2751279\n-0.1193185\n1.0000000\n0.1850584\n0.0323332\n0.2243101\n\n\n#posts\n-0.1611659\n0.0867783\n-0.0625152\n0.1850584\n1.0000000\n0.3436164\n0.1141541\n\n\n#followers\n-0.0635941\n0.0391406\n-0.0275424\n0.0323332\n0.3436164\n1.0000000\n0.0205692\n\n\n#follows\n-0.1667347\n0.0621989\n-0.0526415\n0.2243101\n0.1141541\n0.0205692\n1.0000000\n\n\n\n\n\nParece ser que nums/length fullname y nums/length username puede ser una buena opción para comenzar. La función lm() es la función de R para ajustar modelos lineales (la más importante). La manera de llevarla a la práctica es la siguiente:\n\nfirstModel &lt;- lm(`nums/length fullname` ~ `nums/length username`,\n                 data = all_data)\nfirstModel\n\n\nCall:\nlm(formula = `nums/length fullname` ~ `nums/length username`, \n    data = all_data)\n\nCoefficients:\n           (Intercept)  `nums/length username`  \n             -0.008999                0.307118  \n\n\nPara no tener que especificar siempre el dataset sobre el cual se extraen o usan los atributos, se puede usar attach.\n\nattach(all_data)\nplot(`nums/length username`,`nums/length fullname`)\nabline(firstModel)\n\n\n\n\n\nsummary(firstModel)\n\n\nCall:\nlm(formula = `nums/length fullname` ~ `nums/length username`, \n    data = all_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.27048 -0.06548  0.00900  0.00900  0.77866 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            -0.008999   0.006053  -1.487    0.138    \n`nums/length username`  0.307118   0.022009  13.954   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.127 on 694 degrees of freedom\nMultiple R-squared:  0.2191,    Adjusted R-squared:  0.218 \nF-statistic: 194.7 on 1 and 694 DF,  p-value: &lt; 2.2e-16\n\n\nLa salida del resumen (summary) del modelo de regresión lineal proporciona información importante sobre la ajuste del modelo a los datos y la significancia de las variables predictoras.\n\nResiduals (Residuos): Esta sección muestra estadísticas resumidas sobre los residuos del modelo, que son las diferencias entre los valores observados y los valores predichos por el modelo. Proporciona una idea de cómo se distribuyen los errores de predicción.\nCoefficients (Coeficientes): Esta tabla presenta los coeficientes estimados para cada variable predictora en el modelo. Los coeficientes indican la magnitud y la dirección de la relación entre cada variable predictora y la variable de respuesta. Además, los valores t y los valores p asociados con cada coeficiente ayudan a evaluar la significancia estadística de las variables predictoras.\nMultiple R-squared (R cuadrado múltiple): Este coeficiente de determinación indica la proporción de variabilidad en la variable de respuesta que es explicada por el modelo. Cuanto más cercano sea el R cuadrado a 1, mejor se ajusta el modelo a los datos.\nF-statistic (Estadístico F): Este estadístico se utiliza para probar la significancia global del modelo. Evalúa si al menos una de las variables predictoras tiene un efecto significativo sobre la variable de respuesta. El valor p asociado indica si el modelo en su conjunto es significativo\n\nComo se puede apreciar en el gráfico representado anteriormente, existen muchos puntos dondes nums/length fullname es igual a 0, lo que hace que la precisión de nuestro modelo de regresión se reduzca drásticamente. Una posible solución para esto podría ser eliminar dichos puntos…\n\nall_data_clean &lt;- all_data[all_data$`nums/length fullname` != 0, ]\nsecondModel &lt;- lm(`nums/length fullname` ~ `nums/length username`,\n                 data = all_data_clean)\nsecondModel\n\n\nCall:\nlm(formula = `nums/length fullname` ~ `nums/length username`, \n    data = all_data_clean)\n\nCoefficients:\n           (Intercept)  `nums/length username`  \n               0.09203                 0.75790  \n\n\n\nplot(all_data_clean$`nums/length username`,all_data_clean$`nums/length fullname`)\nabline(secondModel)\n\n\n\n\n\nsummary(secondModel)\n\n\nCall:\nlm(formula = `nums/length fullname` ~ `nums/length username`, \n    data = all_data_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.56382 -0.07045 -0.01698  0.04213  0.33955 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             0.09203    0.03148   2.923  0.00463 ** \n`nums/length username`  0.75790    0.06699  11.314  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1404 on 72 degrees of freedom\nMultiple R-squared:   0.64, Adjusted R-squared:  0.635 \nF-statistic:   128 on 1 and 72 DF,  p-value: &lt; 2.2e-16\n\n\n¡Esto ha mejorado bastante! Este segundo modelo presenta un \\(R^2\\) de 0.64, es decir, el modelo es capaz de acertar los puntos en un 64% de los casos, ademas de presentar un p-value realmente correcto. Si quisieramos ver algunas de las gráficas representativas del modelo…\n\nplot(firstModel)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSe aprecia como la última gráfica, se pueden interpretar las distancias de Cook para identificar observaciones influyentes en el modelo. Una regla general es que si la distancia de Cook para una observación es mayor que 1, esta observación puede tener una influencia desproporcionada en el modelo y podría considerarse influyente. Sin embargo, el umbral para considerar una observación como influyente puede variar según el contexto del problema y la cantidad de datos disponibles. Ademas, en el propio gráfico R nos muestra una serie de puntos etiquetados que representan aquellos que hacen que el modelo pierda eficacia, por lo que una posible solución de mejora del modelo de regresión sería quitarnos del medio dichos puntos.\nPodemos probar ahora a realizar un modelo entre description length y nums/length username.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nall_data_clean_2 &lt;- all_data[all_data$`description length` != 0 & all_data$`nums/length username` != 0, ]\nthirdModel &lt;- lm(log(`nums/length username`) ~ `description length`,\n                 data = all_data_clean_2)\nthirdModel\n\n\nCall:\nlm(formula = log(`nums/length username`) ~ `description length`, \n    data = all_data_clean_2)\n\nCoefficients:\n         (Intercept)  `description length`  \n           -1.360939             -0.002341  \n\nall_data_clean_2 %&gt;%\n  ggplot(aes(x = `description length`, y = `nums/length username`)) +\n  geom_point() + \n  geom_line(aes(x = `description length`, y = predict(thirdModel)))\n\n\n\n\n\nfit0 &lt;- all_data_clean_2$`nums/length username` ~ 1/(1 + all_data_clean_2$`description length`^c)\nthirdModelUpdated &lt;- nls(fit0, data = all_data_clean_2, start = list(c = 1))\n\n\nsummary(thirdModelUpdated)\n\n\nFormula: all_data_clean_2$`nums/length username` ~ 1/(1 + all_data_clean_2$`description length`^c)\n\nParameters:\n  Estimate Std. Error t value Pr(&gt;|t|)    \nc  0.27570    0.02909   9.476 1.86e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.169 on 75 degrees of freedom\n\nNumber of iterations to convergence: 4 \nAchieved convergence tolerance: 3.372e-06\n\n\nHaciendo uso de nls y de una función exponencial hemos logrado obtener un resultado mucho mejor, como se puede ver visualmente.\n\nall_data_clean_2 %&gt;%\n  ggplot(aes(x = `description length`, y = `nums/length username`)) +\n  geom_point() + \n  geom_line(aes(x = `description length`, y = predict(thirdModelUpdated)),color=\"red\")\n\n\n\n\nCon esto terminamos la sección de modelos de regresión. Aunque esta vez hemos encontrado un poco más de dificultades debido a la naturaleza del dataset del cual disponemos, hemos logrado encontrar algunos modelos que muestran realmente información interesante de manera visual entre enfrentamientos de variables de nuestro conjunto de datos. Pasamos ahora a la parte de series temporales, conjuntos de datos que representan observaciones recopiladas en intervalos de tiempo regulares. Este campo de estudio se centra en el análisis, la modelización y la predicción de datos que varían con el tiempo."
  },
  {
    "objectID": "seriestemporales.html",
    "href": "seriestemporales.html",
    "title": "6  Series temporales",
    "section": "",
    "text": "Las series temporales son un componente fundamental en el análisis de datos, que nos permite entender y modelar el comportamiento de variables a lo largo del tiempo. Desde el análisis económico hasta la predicción del clima, las series temporales son utilizadas en una amplia gama de campos para revelar patrones, identificar tendencias y realizar pronósticos.\n\n  \n\nEs cierto que nuestro conjunto de datos no es quizás el mejor para analizar series temporales, ya que parece estar más orientado hacia el análisis de perfiles de redes sociales. Sin embargo, podríamos utilizar algunas de las variables presentes, como el número de publicaciones (#posts), el número de seguidores (#followers), y el número de seguidos (#follows), para realizar un análisis temporal de la actividad de los usuarios en las redes sociales.\n\nlibrary(readr)\ntrain &lt;- read_csv(\"datasets/train.csv\")\n\nRows: 576 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntest &lt;- read_csv(\"datasets/test.csv\")\n\nRows: 120 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nall_data &lt;- rbind(train, test)\n\nUsando la función ts podemos trabajar con series temporales. Los argumentos que recibe suelen ser un vector de datos como primero, un comienzo o \\(start\\) y la frecuencia o \\(frequency\\). En este caso, podríamos probar de la siguiente manera:\n\nserieTemporal &lt;- ts(all_data$`description length`, start = 1, frequency = 50)\nplot(serieTemporal)\n\n\n\n\nAunque como ya comentabamos anteriormente, al tratarse de un conjunto de datos que no presenta una esencia temporal en sus atributos, es complicado que la serie temporal obtenida nos proporcione cierta información útil. No obstante, como ya comentabamos arriba existen algunas tencicas que nos podráin llegar a permitir obtener ciertos resultado. Alguna que se me ocurre podría ser ordenar nuestro conjunto de datos por una de las variables, y mostrar en la serie temporal otra, con la condicion de que ambas presenten cierta correlación entre ellas. Recordando del apartado anterior…\n\npairs(all_data[colnames(all_data)])\n\n\n\nknitr::kable(cor(all_data))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprofile pic\nnums/length username\nfullname words\nnums/length fullname\nname==username\ndescription length\nexternal URL\nprivate\n#posts\n#followers\n#follows\nfake\n\n\n\n\nprofile pic\n1.0000000\n-0.3206651\n0.2198022\n-0.1113861\n-0.1325460\n0.3569033\n0.2280166\n0.1525347\n0.1695865\n0.0597795\n0.1581316\n-0.6245477\n\n\nnums/length username\n-0.3206651\n1.0000000\n-0.2362528\n0.4680883\n0.0608612\n-0.3172081\n-0.2331335\n-0.1043411\n-0.1611659\n-0.0635941\n-0.1667347\n0.5703625\n\n\nfullname words\n0.2198022\n-0.2362528\n1.0000000\n-0.1022177\n-0.0853250\n0.2751279\n0.2038937\n-0.0587288\n0.0867783\n0.0391406\n0.0621989\n-0.3004846\n\n\nnums/length fullname\n-0.1113861\n0.4680883\n-0.1022177\n1.0000000\n0.2600738\n-0.1193185\n-0.0934336\n-0.0750208\n-0.0625152\n-0.0275424\n-0.0526415\n0.2509043\n\n\nname==username\n-0.1325460\n0.0608612\n-0.0853250\n0.2600738\n1.0000000\n-0.0457051\n-0.0447284\n0.0282962\n-0.0504453\n-0.0180985\n-0.0071267\n0.1621392\n\n\ndescription length\n0.3569033\n-0.3172081\n0.2751279\n-0.1193185\n-0.0457051\n1.0000000\n0.4897756\n-0.0313382\n0.1850584\n0.0323332\n0.2243101\n-0.4788901\n\n\nexternal URL\n0.2280166\n-0.2331335\n0.2038937\n-0.0934336\n-0.0447284\n0.4897756\n1.0000000\n-0.1517716\n0.1988325\n0.0533685\n0.1304888\n-0.3578252\n\n\nprivate\n0.1525347\n-0.1043411\n-0.0587288\n-0.0750208\n0.0282962\n-0.0313382\n-0.1517716\n1.0000000\n-0.0717481\n-0.0715365\n-0.0620013\n-0.1339719\n\n\n#posts\n0.1695865\n-0.1611659\n0.0867783\n-0.0625152\n-0.0504453\n0.1850584\n0.1988325\n-0.0717481\n1.0000000\n0.3436164\n0.1141541\n-0.2506252\n\n\n#followers\n0.0597795\n-0.0635941\n0.0391406\n-0.0275424\n-0.0180985\n0.0323332\n0.0533685\n-0.0715365\n0.3436164\n1.0000000\n0.0205692\n-0.0938015\n\n\n#follows\n0.1581316\n-0.1667347\n0.0621989\n-0.0526415\n-0.0071267\n0.2243101\n0.1304888\n-0.0620013\n0.1141541\n0.0205692\n1.0000000\n-0.1542582\n\n\nfake\n-0.6245477\n0.5703625\n-0.3004846\n0.2509043\n0.1621392\n-0.4788901\n-0.3578252\n-0.1339719\n-0.2506252\n-0.0938015\n-0.1542582\n1.0000000\n\n\n\n\n\nParece ser que \\(nums/length \\hspace{1mm} username\\) y \\(nums/length \\hspace{1mm} fullname\\) podría llegar a ser la mejor opción a escoger, presentando este par de atributos un 0.47 de correlación mutua.\n\npairs(all_data[c(\"nums/length username\", \"nums/length fullname\")])\n\n\n\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nall_data &lt;- all_data %&gt;%\n            arrange(all_data$`nums/length username`)\nserieTemporal &lt;- ts(all_data$`nums/length fullname`, start = 1)\nplot(serieTemporal)\n\n\n\n\nSi nos damos cuenta, ahora en la gráfica se aprecia claramente como la esencia temporal de la serie es controlada por la variable que hemos usado para ordenar el dataset, y el numero de datos que presenta la serie es igual al del conjunto de datos, ya que para cada par de valores \\(username\\) - \\(fullname\\) hemos usado el primero para tiempo y el segundo como inferencia de la serie.\n\nlength(serieTemporal) == nrow(all_data)\n\n[1] TRUE\n\n\n\nsummary(serieTemporal)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.00000 0.00000 0.04217 0.00000 1.00000 \n\nmean(all_data$`nums/length fullname`)\n\n[1] 0.04216954\n\n\n\naggregate(serieTemporal)\n\nTime Series:\nStart = 1 \nEnd = 696 \nFrequency = 1 \n  [1] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n [16] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n [31] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n [46] 0.00 0.00 0.12 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n [61] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n [76] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n [91] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.08 0.00 0.00 0.00\n[106] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[121] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[136] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[151] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.25 0.33 0.00 0.00 0.00 0.00\n[166] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[181] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[196] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[211] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[226] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[241] 0.00 0.00 0.00 0.40 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[256] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[271] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[286] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.25 0.00\n[301] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[316] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.30 0.00 0.00 0.00 0.00 0.00 0.00\n[331] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[346] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[361] 0.00 0.25 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[376] 0.00 0.00 0.00 0.00 0.00 0.00 0.10 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[391] 0.00 0.11 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[406] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[421] 0.00 0.12 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[436] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.20 0.00 0.00 0.00 0.33 0.00 0.00 0.00\n[451] 0.00 0.00 0.00 0.00 0.14 0.00 0.22 0.00 0.22 0.00 0.33 0.00 0.00 0.24 0.00\n[466] 0.24 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.18\n[481] 0.00 0.00 0.00 0.00 0.00 0.27 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.24 0.00\n[496] 0.00 0.00 0.00 0.00 0.00 0.00 0.33 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[511] 0.00 0.36 0.31 0.31 0.00 0.00 0.31 0.00 0.00 0.33 0.00 0.00 0.00 0.00 0.00\n[526] 0.00 0.33 0.00 0.38 0.33 0.00 0.00 0.00 0.00 0.33 0.00 0.00 0.25 0.00 0.00\n[541] 0.00 0.22 0.00 0.00 0.33 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[556] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.40 0.00 0.00 0.00 0.00 0.00 0.33 0.00\n[571] 0.00 0.33 0.00 0.33 0.25 0.00 0.00 0.00 0.00 0.00 0.00 0.40 0.00 0.00 0.00\n[586] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.40 0.00 0.00 0.00 0.43 0.00\n[601] 0.00 0.00 0.43 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n[616] 0.44 0.00 0.00 0.00 0.25 0.00 0.40 0.46 0.00 0.50 0.00 0.00 0.00 0.00 0.00\n[631] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.33 0.40 0.50 0.40 0.00 0.00 0.40 0.00\n[646] 0.00 0.00 0.00 0.00 0.29 0.00 0.44 0.56 0.00 0.00 0.00 0.00 0.40 0.00 0.00\n[661] 0.57 0.00 0.00 0.00 0.36 0.00 0.44 0.50 0.00 0.40 0.40 0.00 0.00 0.00 0.00\n[676] 0.00 0.50 0.00 0.00 1.00 0.00 0.00 0.18 0.00 1.00 1.00 1.00 1.00 0.89 0.00\n[691] 0.00 1.00 0.00 0.00 0.00 1.00\n\n\n\nlibrary(ggplot2)\nlibrary(forecast)\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\nautoplot(serieTemporal)\n\n\n\n\nDebido a la naturaleza de nuestro conjunto de datos, no disponíamos de partida atributos que tuvieran rasgos temporales, por lo que aplicar el campo de series temporales para nuestro dataset se convierte en una tarea realmente compleja."
  },
  {
    "objectID": "otrastecnicas.html",
    "href": "otrastecnicas.html",
    "title": "7  Otras técnicas",
    "section": "",
    "text": "En el análisis de datos, es fundamental utilizar una variedad de técnicas para obtener una comprensión completa y detallada de los datos y sus patrones subyacentes. Hasta ahora, hemos realizado un análisis exploratorio de datos, visualización de datos, aplicado reglas de asociación, análisis de correspondencias (FCA), regresión y análisis de series temporales. Cada una de estas técnicas ha proporcionado perspectivas valiosas sobre diferentes aspectos del conjunto de datos.\nConcretamente, en esta última parte que nos espera vamos a centrarnos en técnicas más alejadas de los contenidos de la asignatura, pero que igualmente nos permiten tener una visión más profunda y concreta de los patrones de nuestro conjunto de datos. Concretamente, dentro del Machine Learning existen muchas técnicas realmente útiles y que permiten a los desarrolladores encontrar modelos predictivos, sin necesidad de preocuparse por la propia implementación interna y la correlación de variables, ya que son los propios paquetes y sus funciones los que se encargan de ello.\nConcretamente, vamos a probar party. Los árboles de decisión son una herramienta poderosa para la clasificación y la regresión. Su estructura intuitiva y gráfica permite descomponer el espacio de características en regiones disjuntas, facilitando la interpretación y visualización de las decisiones tomadas. Utilizaremos este paquete en R para construir y evaluar modelos de árboles de decisión. Este paquete implementa árboles de decisión condicionales que son capaces de manejar datos con estructuras complejas y relaciones no lineales de manera eficiente.\nPor otro lado, optaremos por neuralnet, un paquete que nos permitirá construir y entrenar redes neuronales artificiales con una o más capas ocultas. Este enfoque es ideal para problemas donde las relaciones entre las variables predictoras y la variable objetivo no son evidentes o lineales.\n\nlibrary(readr)\ntrain &lt;- read_csv(\"datasets/train.csv\")\n\nRows: 576 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntest &lt;- read_csv(\"datasets/test.csv\")\n\nRows: 120 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nEsta vez, no es necesario construir \\(alldata\\) como la union por filas de ambos datasets, ya que aprovechando que el autor del conjunto de datos de Kaggle realizó el split por nosotros, tomaremos el primero de los datasets a modo de entrenar el arbol de decision o red neuronal, y el segundo de ellos para probar como de bueno son ambos modelos con respecto a los “label” que disponemos.\n\nlibrary(party)\n\nLoading required package: grid\n\n\nLoading required package: mvtnorm\n\n\nLoading required package: modeltools\n\n\nLoading required package: stats4\n\n\nLoading required package: strucchange\n\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\nLoading required package: sandwich\n\nlibrary(neuralnet)\nlibrary(caret)\n\nLoading required package: ggplot2\n\n\nLoading required package: lattice\n\ntree &lt;- ctree(fake ~ .,\n              data = train)\n\nCon ctree resulta realmente sencillo construir el árbol de decisión, ya que sus parámetros son simplemente las columnas que queremos evaluar o usar en el modelo, y el dataset al cual corresponden estas.\n\nplot(tree, type = \"simple\")\n\n\n\nplot(tree, type = \"extended\")\n\n\n\n\nSe puede apreciar como ambos dibujos nos dan una visión completa del modelo del cual disponemos. Depende del parametro “type”, un carácter que especifica la complejidad del gráfico: extendido intenta visualizar la distribución de la variable de respuesta en cada nodo terminal, mientras que simple sólo proporciona información resumida.\nSe puede apreciar claramente como según se van tomando ciertos valores de los atributos, el propio arbol de decision (como su propio nombre indica) va decidiendo que camino de nodos tomar hasta llegar a uno que no tiene hijos, caso en el cual el camino se ha terminado y el arbol ha tomado la decision de la clasificacion. Ahora bien, necesitamos conocer cómo de bueno es el árbol…\n\npredicciones &lt;- predict(tree, newdata = test)\nhead(cbind(predicciones, test$fake))\n\n          fake  \n[1,] 0.2500000 0\n[2,] 0.1380952 0\n[3,] 0.1380952 0\n[4,] 0.1380952 0\n[5,] 0.9315068 0\n[6,] 0.1380952 0\n\naciertos &lt;- sum(round(predicciones) == test$fake)\naciertos\n\n[1] 106\n\nfallos &lt;- sum(round(predicciones) != test$fake)\nfallos\n\n[1] 14\n\nporcentajeAcierto &lt;- (aciertos / nrow(test)) * 100\nporcentajeAcierto\n\n[1] 88.33333\n\n\nEl árbol compone un modelo de clasificación realmente efectivo para nuestro conjunto de datos, obteniendose un 89% de aciertos para el dataset de “test”, lo cual es realmente bueno. Vamos a ver ahora que son capaces de hacer las redes neuronales con \\(neuralnet\\).\n\nattach(train)\n\ncolnames(train)[2] &lt;- \"numslength_username\"\ncolnames(test)[2] &lt;- \"numslength_username\"\ncolnames(train)[4] &lt;- \"numslength_fullname\"\ncolnames(test)[4] &lt;- \"numslength_fullname\"\n\nNN &lt;- neuralnet(numslength_username ~ numslength_fullname,\n                data = train,hidden = c(5,3))\n\nneuralnet:::plot.nn(NN)\n\n\n  \n\nDe primeras, apreciamos en el “plot” que disponemos de una red neuronal de 3 capas ocultas (hidden layers), así como lo hemos indicado en el parámetro \\(hidden\\). Si quisieramos probar como de buena es la red, podríamos realizar lo siguiente:\n\npred &lt;- neuralnet::compute(NN, test)\nhead(pred$net.result, n = 15)\n\n           [,1]\n [1,] 0.3390816\n [2,] 0.1402752\n [3,] 0.1402752\n [4,] 0.1402752\n [5,] 0.1402752\n [6,] 0.1402752\n [7,] 0.1402752\n [8,] 0.1402752\n [9,] 0.1402752\n[10,] 0.1402752\n[11,] 0.1402752\n[12,] 0.1402752\n[13,] 0.1402752\n[14,] 0.1402752\n[15,] 0.1402752\n\nhead(cbind(pred$net.result, test$numslength_username), n = 15)\n\n           [,1] [,2]\n [1,] 0.3390816 0.33\n [2,] 0.1402752 0.00\n [3,] 0.1402752 0.00\n [4,] 0.1402752 0.00\n [5,] 0.1402752 0.50\n [6,] 0.1402752 0.00\n [7,] 0.1402752 0.00\n [8,] 0.1402752 0.00\n [9,] 0.1402752 0.00\n[10,] 0.1402752 0.00\n[11,] 0.1402752 0.00\n[12,] 0.1402752 0.14\n[13,] 0.1402752 0.14\n[14,] 0.1402752 0.33\n[15,] 0.1402752 0.10\n\nmse &lt;- mean((pred$net.result - test$numslength_username)^2)\nmse\n\n[1] 0.03365679\n\nmae &lt;- mean(abs(pred$net.result - test$numslength_username))\nmae\n\n[1] 0.1531171\n\n\nUn error cuadrático medio (MSE) de 0.03363798 es una métrica útil para evaluar el rendimiento de tu modelo. El MSE mide la cantidad promedio por la cual las predicciones de un modelo difieren de los valores reales al cuadrado. Cuanto menor sea el MSE, mejor será el rendimiento del modelo.\nEn nuestro caso, un MSE de 0.03363798 indica que, en promedio, las predicciones del modelo difieren de los valores reales por aproximadamente 0.03363798 unidades al cuadrado. Esto sugiere que el modelo parece estar haciendo buenas predicciones en el conjunto de prueba, lo cual es realmente positivo.\nPodríamos probar a incluir como inferencia el atributo \\(fake\\) del conjunto de datos, que como ya hemos comentado a lo largo del “book” se trata del atributo “objetivo”.\n\ntrain &lt;- read_csv(\"datasets/train.csv\")\n\nRows: 576 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntest &lt;- read_csv(\"datasets/test.csv\")\n\nRows: 120 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncolnames(train)[2] &lt;- \"numslength_username\"\ncolnames(test)[2] &lt;- \"numslength_username\"\ncolnames(train)[4] &lt;- \"numslength_fullname\"\ncolnames(test)[4] &lt;- \"numslength_fullname\"\ncolnames(train)[1] &lt;- \"profilepic\"\ncolnames(test)[1] &lt;- \"profilepic\"\ncolnames(train)[10] &lt;- \"followers\"\ncolnames(test)[10] &lt;- \"followers\"\n\ncolnames(train)\n\n [1] \"profilepic\"          \"numslength_username\" \"fullname words\"     \n [4] \"numslength_fullname\" \"name==username\"      \"description length\" \n [7] \"external URL\"        \"private\"             \"#posts\"             \n[10] \"followers\"           \"#follows\"            \"fake\"               \n\nattach(train)\n\nThe following objects are masked from train (pos = 3):\n\n    #follows, #posts, description length, external URL, fake, fullname\n    words, name==username, private\n\nNN &lt;- neuralnet(fake ~ numslength_username + numslength_fullname + profilepic + followers,\n                data = train,hidden = c(4,3), linear.output = FALSE, act.fct = \"logistic\", stepmax = 1e6)\n\nSi lo que vamos a crear se trata de una red neuronal orientada a computo de problemas de clasificacio, en el constructor de \\(neuralnet\\) es necesario indicarlo a traves del atributo “act.fct”.\n\nneuralnet:::plot.nn(NN)\n\n\n  \n\n\nNN$weights\n\n[[1]]\n[[1]][[1]]\n         [,1]     [,2]         [,3]        [,4]\n[1,] 36.76532 36.81951 -2.972469583  -23.023084\n[2,] 35.06320 32.59756 -2.500439406 -281.055120\n[3,] 24.87034 23.98491 -3.405068673 -300.391502\n[4,] 18.82215 17.87662  2.395577755   15.711377\n[5,] 18.89273 17.32850  0.004449387    1.396627\n\n[[1]][[2]]\n         [,1]        [,2]      [,3]\n[1,] 10.77243 -0.02887038  9.889192\n[2,] 14.26213 -0.95965711 13.594037\n[3,] 11.76496 -2.48185248 13.278247\n[4,] 20.14241  5.87857684 27.222118\n[5,] 12.70155  2.13404791 11.874503\n\n[[1]][[3]]\n           [,1]\n[1,]  1.0876215\n[2,]  4.9292739\n[3,] -9.9903776\n[4,]  0.9154433\n\n\nEstos son los pesos que ha aprendido la red, que son los parámetros clave que la red ajusta durante el proceso de entrenamiento para aprender a realizar predicciones. Estos pesos determinan la importancia de cada entrada en la activación de las neuronas y, en última instancia, en la salida de la red neuronal.\n\npred &lt;- neuralnet::compute(NN, test[, c(\"numslength_username\", \"numslength_fullname\", \"profilepic\",\"followers\")])\n\npredicted_classes &lt;- ifelse(pred$net.result &gt; 0.5, 1, 0)\n\nconf_matrix &lt;- confusionMatrix(as.factor(predicted_classes), as.factor(test$fake))\nconf_matrix\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  0  1\n         0 56 12\n         1  4 48\n                                          \n               Accuracy : 0.8667          \n                 95% CI : (0.7925, 0.9218)\n    No Information Rate : 0.5             \n    P-Value [Acc &gt; NIR] : &lt; 2e-16         \n                                          \n                  Kappa : 0.7333          \n                                          \n Mcnemar's Test P-Value : 0.08012         \n                                          \n            Sensitivity : 0.9333          \n            Specificity : 0.8000          \n         Pos Pred Value : 0.8235          \n         Neg Pred Value : 0.9231          \n             Prevalence : 0.5000          \n         Detection Rate : 0.4667          \n   Detection Prevalence : 0.5667          \n      Balanced Accuracy : 0.8667          \n                                          \n       'Positive' Class : 0               \n                                          \n\nmse &lt;- mean((pred$net.result - test$fake)^2)\nmse\n\n[1] 0.1094549\n\n\nDe nuevo, hemos logrado un modelo realmente potente, que presenta una exactitud general (accuracy) del 88% y un intervalo de confianza del 95% para la exactitud varía entre 80.22% y 92.83%, indicando la certeza del rendimiento del modelo. El p-valor es realmente pequeño, lo cual tambien es interesante. Si quisieramos ahora conocer que dictaminaría nuestro modelo sobre un nuevo dato de entrada, podríamos hacer lo siguiente. Supongamos que queremos saber si una cuenta de Instagram con un 0.2 de “numslength_username”, un 0 de “numslength_fullname”, 1 de “profilepic” y 845 “followers”, ¿sería fake?\n\nnuevo_dato &lt;- data.frame(numslength_username = 0.2, \n                         numslength_fullname = 0, \n                         profilepic = 1, \n                         followers = 845)\n\npred_nuevo_dato &lt;- compute(NN, nuevo_dato)\n\n# Convertir la salida de la red neuronal en una predicción de clase (umbral de 0.5)\nprediccion &lt;- ifelse(pred_nuevo_dato$net.result &gt; 0.5, 1, 0)\npred_nuevo_dato$net.result\n\n          [,1]\n[1,] 0.0518864\n\nprediccion\n\n     [,1]\n[1,]    0\n\n\nNuestra red neuronal dicta que la cuenta no va a ser falsa, además con un 91% de certeza (1 - pred$net.result)."
  },
  {
    "objectID": "intro.html#aver-que-sale",
    "href": "intro.html#aver-que-sale",
    "title": "1  Introduction",
    "section": "1.1 Aver que sale",
    "text": "1.1 Aver que sale\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "analisisexploratorio.html#titulo-aqui-dplyr",
    "href": "analisisexploratorio.html#titulo-aqui-dplyr",
    "title": "1  Análisis exploratorio de datos",
    "section": "1.1 Titulo aqui … dplyr",
    "text": "1.1 Titulo aqui … dplyr\ntexto aqui…\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union"
  },
  {
    "objectID": "analisisexploratorio.html#comenzando-el-análisiscon-dplyr",
    "href": "analisisexploratorio.html#comenzando-el-análisiscon-dplyr",
    "title": "1  Análisis exploratorio de datos",
    "section": "1.1 Comenzando el análisis…con dplyr",
    "text": "1.1 Comenzando el análisis…con dplyr\ntexto aqui…\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union"
  },
  {
    "objectID": "analisisexploratorio.html#comenzando-el-análisis-con-dplyr",
    "href": "analisisexploratorio.html#comenzando-el-análisis-con-dplyr",
    "title": "1  Análisis exploratorio de datos",
    "section": "1.1 Comenzando el análisis con dplyr",
    "text": "1.1 Comenzando el análisis con dplyr\nComo no podía ser de otra forma, comenzaremos nuestra aventura haciendo uso de dplyr. Desarrollado por Hadley Wickham, es un paquete diseñado para facilitar y agilizar las tareas de manipulación, transformación y filtrado de datos en R. Con una sintaxis clara y concisa, “dplyr” proporciona una serie de funciones intuitivas que permiten realizar operaciones comunes de manera eficiente y elegante.\nEn primer lugar cargaremos dicho paquete, y comenzaremos a aplicar ciertas técnicas a nuestro dataset…\n\nlibrary(dplyr)\nsummary(all_data)\n\n  profile pic     nums/length username fullname words   nums/length fullname\n Min.   :0.0000   Min.   :0.0000       Min.   : 0.000   Min.   :0.00000     \n 1st Qu.:0.0000   1st Qu.:0.0000       1st Qu.: 1.000   1st Qu.:0.00000     \n Median :1.0000   Median :0.0000       Median : 1.000   Median :0.00000     \n Mean   :0.7112   Mean   :0.1666       Mean   : 1.476   Mean   :0.04217     \n 3rd Qu.:1.0000   3rd Qu.:0.3300       3rd Qu.: 2.000   3rd Qu.:0.00000     \n Max.   :1.0000   Max.   :0.9200       Max.   :12.000   Max.   :1.00000     \n name==username    description length  external URL       private      \n Min.   :0.00000   Min.   :  0.00     Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.00000   1st Qu.:  0.00     1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.00000   Median :  0.00     Median :0.0000   Median :0.0000  \n Mean   :0.03592   Mean   : 23.41     Mean   :0.1135   Mean   :0.3693  \n 3rd Qu.:0.00000   3rd Qu.: 35.00     3rd Qu.:0.0000   3rd Qu.:1.0000  \n Max.   :1.00000   Max.   :150.00     Max.   :1.0000   Max.   :1.0000  \n     #posts         #followers          #follows           fake    \n Min.   :   0.0   Min.   :       0   Min.   :   0.0   Min.   :0.0  \n 1st Qu.:   0.0   1st Qu.:      42   1st Qu.:  61.0   1st Qu.:0.0  \n Median :   9.0   Median :     166   Median : 252.0   Median :0.5  \n Mean   : 103.2   Mean   :   79150   Mean   : 555.1   Mean   :0.5  \n 3rd Qu.:  77.0   3rd Qu.:     693   3rd Qu.: 601.8   3rd Qu.:1.0  \n Max.   :7389.0   Max.   :15338538   Max.   :7500.0   Max.   :1.0  \n\n\n\nnumberOfWithPicProfiles &lt;- all_data %&gt;%\n                            filter(`profile pic` == 1) %&gt;%\n                            summarise(total = n())\nc(with = numberOfWithPicProfiles$total, without = nrow(all_data) - numberOfWithPicProfiles$total)\n\n   with without \n    495     201 \n\n\n\nporcentajeWith &lt;-  numberOfWithPicProfiles$total / nrow(all_data)\nc(with = porcentajeWith, without = 1 - porcentajeWith)\n\n     with   without \n0.7112069 0.2887931 \n\n\nPodemos apreciar como un alrededor del 70% de los datos que se nos ha proporcionado en el dataframe son de cuentas que presentan una foto de perfil. ¿Y si quisieramos saber cuantos de ellos tienen cuentas fake?\n\npic_fake &lt;- all_data %&gt;%\n            group_by(`profile pic`) %&gt;%\n            summarise(fake = sum(fake == 1),\n                      nofake = n() - fake)\nknitr::kable(pic_fake)\n\n\n\n\nprofile pic\nfake\nnofake\n\n\n\n\n0\n199\n2\n\n\n1\n149\n346\n\n\n\n\n\nYa hemos comenzado a extraer información, ¡es nuestro primer paso! Vemos en la salida del último “chunk” como para un casi 100% de las entradas de nuestra tabla donde la cuenta no tiene foto de perfil, se trata de una cuenta de Instagram fake (lo cual tiene cierto sentido, porque el primer paso para desconfiar de alguien que comienza a seguirnos es que no presenta una foto en su perfil), mientras que para aquellas cuentan que contienen foto de perfil, el reconocer sobre la vericidad de la cuenta se hace más complicado. Aún asi, ¡vamos a seguir trabajando en ello! Centrémonos en las cuentas que tienen foto de perfil:\n\nvaloresPublicaciones &lt;- sort(unique(all_data$`#posts`))\n\npuntos_corte &lt;- quantile(valoresPublicaciones, probs = seq(0, 1, length.out = 10 + 1), na.rm = TRUE)\n\npublicacionesPerfilesConFoto &lt;- all_data %&gt;%\n          mutate(post_group = cut(`#posts`, breaks = puntos_corte)) %&gt;%\n          filter(`profile pic` == 1) %&gt;%\n          group_by(post_group) %&gt;%\n          summarise(fake = sum(fake == 1),\n                    no_fake = n() - fake)\nknitr::kable(publicacionesPerfilesConFoto)\n\n\n\n\npost_group\nfake\nno_fake\n\n\n\n\n(0,21]\n86\n97\n\n\n(21,43]\n14\n35\n\n\n(43,72]\n5\n40\n\n\n(72,100]\n4\n32\n\n\n(100,141]\n5\n22\n\n\n(141,209]\n1\n27\n\n\n(209,274]\n0\n23\n\n\n(274,396]\n1\n22\n\n\n(396,664]\n0\n21\n\n\n(664,7.39e+03]\n0\n21\n\n\nNA\n33\n6\n\n\n\n\n\nPodemos ver como, haciendo uso de la función quantile para dividir en rangos de publicaciones a los usuarios de nuestra tabla, se puede apreciar una clara disminución del número de cuentas fake a medida que se aumenta el número de publicaciones. Esto, “traducido a lenguaje coloquial”, sería algo así como “esta cuenta no puede ser fake, ¡ha subido demasiadas cosas!”. Realmente esta conclusión no es del todo fiable, ya que únicamente el número de publicaciones que una cuenta tenga no nos sirve para extraer información definitiva.\n\nmedidasCuentas &lt;- all_data %&gt;%\n                  group_by(fake) %&gt;%\n                  summarise(meanNLusername = mean(`nums/length username`),\n                            maxNLusername = max(`nums/length username`),\n                            meanWordsFL = mean(`fullname words`),\n                            meanDescrLen = mean(`description length`),\n                            name_eq_usern = sum(`name==username` == 1)/n(),\n                            name_neq_usern = sum(`name==username` == 0)/n())\nknitr::kable(medidasCuentas)\n\n\n\n\n\n\n\n\n\n\n\n\n\nfake\nmeanNLusername\nmaxNLusername\nmeanWordsFL\nmeanDescrLen\nname_eq_usern\nname_neq_usern\n\n\n\n\n0\n0.0418103\n0.50\n1.798851\n41.882184\n0.0057471\n0.9942529\n\n\n1\n0.2914080\n0.92\n1.152299\n4.942529\n0.0660920\n0.9339080\n\n\n\n\n\nLa salida de esta última aplicación de “dplyr” comienza ya a especificarnos un poco más. Si nos fijamos, hemos dividido la salida en 2 filas, una para cada una de las inferencias que buscamos de manera general: cuentas fake o no fake. Para cada una de ellas hemos computado diferentes métricas que nos van a resultar realmente útiles. Vemos como existe una gran diferencia entre la media de caracteres numéricos sobre la longitud del nombre de usuario en cuentas que son fake (porque sí, john323243598362 nos genera más sospecha que pedrito03). Además, para fortalecer dicha métrica, he mostrado también justo a su derecha los valores máximos para dicho atributos en ambos tipos de cuentas, obteniéndose un 0.5 en no fake y un 0.92 en fake, es decir, el 92% de los caracteres de algun usuario fake eran números, lo cual a priori parece una “locura”.\nNo solo tenemos eso, por lo general las cuentas fake presentan muchas menos palabras en sus nombres completos o dichas cuentas presentan normalmente un mayor porcentaje de igualdad entre “username” y nombre completo. Por último, la métrica más abultada, la longitud de las descripciones de las cuentas. La media de este atributo en cuentas fake es de 4 palabras, mientras que en las no fake es de 41.\n\notherMetrics &lt;- all_data %&gt;%\n          group_by(fake) %&gt;%\n          summarise(meanFollowers = mean(`#followers`),\n                    meanFollows = mean(`#follows`),\n                    private = sum(private == 1),\n                    porcPrivate = private / n() * 100,\n                    notprivate = n() - private,\n                    porcNotPrivate = notprivate / n() * 100)\nknitr::kable(otherMetrics)\n\n\n\n\n\n\n\n\n\n\n\n\n\nfake\nmeanFollowers\nmeanFollows\nprivate\nporcPrivate\nnotprivate\nporcNotPrivate\n\n\n\n\n0\n158157.1868\n712.8736\n151\n43.39080\n197\n56.60920\n\n\n1\n142.6236\n397.2989\n106\n30.45977\n242\n69.54023\n\n\n\n\n\nHemos usado ahora otras métricas, las cuales nos siguen dado realmente información relevante sobre el dataset que estamos tratando. Concretamente vemos como la media de seguidores que presentan los perfiles no fake de Instagram es casi 1000 veces más que el de las fake, siendo estas 160.000 y 142 correspondientemente. Al igual, ocurre algo similar con el número de seguidos, donde la diferencia quizás no es tan abultada, aunque sí notable. Por último, en cuanto al atributo de la privacidad de la cuenta o perfil, un 30% de las cuentas fake son privadas frente a un 70% de cuentas públicas. (lo cual es lógico pensar ya que el fin de una cuenta fake no es ocultar nada, caso que ocurre en las cuentas de personas reales, que prefieren ocultar su privacidad y ser visibles solo para personas cercanas y/o conocidas). De esta última razón viene el 44% de cuentas privadas frente a un 56% de públicas en cuentas verdaderas."
  },
  {
    "objectID": "analisisexploratorio.html#un-poco-de-x-me-gusaria-aquí-meter-otro-punto",
    "href": "analisisexploratorio.html#un-poco-de-x-me-gusaria-aquí-meter-otro-punto",
    "title": "1  Análisis exploratorio de datos",
    "section": "1.2 Un poco de X (me gusaria aquí meter otro punto)",
    "text": "1.2 Un poco de X (me gusaria aquí meter otro punto)\nBlablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla.\nConsidero que los pasos dados hasta ahora pueden conformar de manera completa un análisis exploratorio de datos del dataset que nos concierne. Sin embargo, esto no ha hecho más que empezar, porque los métodos de visualización visto en la asignatura nos van a permitir ver de manera visual y clara todo lo que hemos ido detallando con “dplyr”, y mucho más…"
  },
  {
    "objectID": "visualizaciondatos.html#veamos-qué-es-capaz-de-hacer-ggplot",
    "href": "visualizaciondatos.html#veamos-qué-es-capaz-de-hacer-ggplot",
    "title": "2  Visualización de datos",
    "section": "2.1 Veamos qué es capaz de hacer ggplot",
    "text": "2.1 Veamos qué es capaz de hacer ggplot\nEntre las diversas herramientas disponibles para la visualización de datos, una de las más poderosas y versátiles es ggplot2, una librería en R que ofrece una manera elegante y flexible de crear gráficos de alta calidad. Desarrollada por Hadley Wickham (sí, otra vez él), ggplot2 se basa en la filosofía de ‘The Grammar of Graphics’, que se centra en descomponer los gráficos en componentes fundamentales para construir visualizaciones de datos de manera intuitiva y estructurada.\nLa fortaleza de ggplot2 radica en su enfoque declarativo, donde los usuarios describen qué quieren representar y cómo, en lugar de preocuparse por los detalles técnicos de implementación. Con ggplot2, podemos crear una amplia variedad de gráficos, desde simples diagramas de dispersión hasta complejas visualizaciones de datos multivariados, con un código conciso y legible.\nEn este libro, exploraremos los conceptos básicos de ggplot2 y aprenderemos cómo utilizar esta potente herramienta para crear visualizaciones impactantes. Comenzaremos primero por importar las librerías necesarias.\n\nlibrary(readr)\ntrain &lt;- read_csv(\"datasets/train.csv\")\n\nRows: 576 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntest &lt;- read_csv(\"datasets/test.csv\")\n\nRows: 120 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (12): profile pic, nums/length username, fullname words, nums/length ful...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nall_data &lt;- rbind(train, test)\nlibrary(ggplot2)\n\nUna vez hemos importado “ggplot2”, podemos proceder a hacer uso de las múltiples funcionalidades que nos ofrece. Para tantear el terreno, podemos ver algunas pequeñas cosas que es capaz de hacer.\n\nggplot(data = all_data, aes(x = `nums/length username`)) +\n  geom_histogram(binwidth = 0.1, fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Histograma de proporciones de dígitos en los nombres\",\n       x = \"Proporción de dígitos por longitud de nombre de usuario\",\n       y = \"Frecuencia\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\nVemos en el anterior gráfico de histogramas un recuento de frecuencia de cuentas para los distintos valores de proporción dígitos-longitud de username. Se puede ver claramente como las cuentas que predominan son aquellas que no presentan ningún dígito en su nombre de usuario.\nCuando se utiliza la función geom_histogram(), el valor predeterminado para el argumento “stat” es “bin”, lo que significa que ggplot2 calculará automáticamente la frecuencia (o el recuento) de observaciones en cada intervalo de clase y representará estas frecuencias en el eje y del histograma. Continuemos explorando qué más podemos hacer.\nPodemos ver también la distrubicuón de datos en nuestro dataset que presentan cuentas fake y verdaderas:\n\n# Contar la cantidad de cuentas falsas y no falsas\nfake_counts &lt;- table(all_data$fake)\n\n# Gráfico de pastel\npie(fake_counts, labels = c(\"No Falsa\", \"Falsa\"), col = c(\"skyblue\", \"salmon\"),\n    main = \"Proporción de Cuentas Falsas vs. No Falsas\")\n\n\n\n\n¿Qué tal si vemos de manera visual cuantás cuentas de nuestro dataset pertenecen al grupo de privadas y cuántas a públicas? Además le asociaremos mediante scale_fill_manual distintos colores para cada uno de los grupos…\n\n# Diagrama de dispersión: Relación entre #followers y #posts\nggplot(data = all_data, aes(x = private, fill = as.factor(private))) +\n  geom_bar() +\n  labs(title = \"Cuentas Privadas vs Públicas\",\n       x = \"Cuenta privada (0 = No, 1 = Sí)\",\n       y = \"Cantidad\") +\n  scale_fill_manual(values = c(\"skyblue\", \"salmon\"), \n                    name = \"Tipo de Cuenta\",  # Cambiar el texto en la leyenda\n                    labels = c(\"No\", \"Sí\")) +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\nDe manera equivalente, existe una función denominada hist(), que nos podría haber servido para el mismo propósito…\n\nhist(all_data$private)\n\n\n\n\nComo vemos, está siendo muy habitual en los gráficos ver el título de los mismo de manera centrada con respecto a la representación. Esto lo logramos con plot.title, que se trata de un argumento de theme, una función que te permite personalizar diversos aspectos de la apariencia de tu gráfico, como el color de fondo, los márgenes, las etiquetas de los ejes, la posición del título, entre otros.\nPodemos pasar ahora a ver un poco de puntos, que suele ser lo mas normal. Ya veremos más adelante en la sección de regresión, que se tratará de un gráfico realmente representativo, e importante para poder modelar rectas o modelos que nos permitan realizar estimaciones en el futuro para nuevos datos entrantes sobre cuentas de Instagram.\n\nggplot(all_data, aes(x = `#followers`, y = `#posts`)) +\n  geom_point(color = \"darkblue\") +\n  labs(x = \"Número de Seguidores\", y = \"Número de Publicaciones\") +\n  ggtitle(\"Relación entre Seguidores y Publicaciones\")\n\n\n\n\n¡Ups, algo ha ido mal! Existen una serie de puntos que están haciendo que ggplot trate de adaptar el gráfico lo mejor posible a todo el dataset, pero como dichos valores de número de seguidores son demasiado altos con respecto al resto, la gráfica resultante es lo que se ve por pantalla, nada claro. Existen varias manera de poder darle solución a esto.\nLa primera de ellas podría ser, detectar cuáles son dichos puntos, y cortar de raiz el problema. Eliminarlos del dataset y ver si el nuevo dataset es más apto a ser representado mediante geom_point(). Como vemos en el gráfico inútil, son 6 los puntos que nos están poniendo piedras en el camino.\n\n# Como realmente a la hora de representar un dataset mediante un gráfico\n# de puntos no nos importa si está ordenado por algún atributo, no va\n# a influir trabajar en este chunk con un dataset con un orden distintos.\n\ndatos_ordenados &lt;- all_data[order(all_data$`#followers`, decreasing = TRUE), ]\n\ndatosSinLosPrimeros6 &lt;- datos_ordenados[-(1:6), ]\n\nggplot(datosSinLosPrimeros6, aes(x = `#followers`, y = `#posts`)) +\n  geom_point(color = \"darkblue\") +\n  labs(x = \"Número de Seguidores\", y = \"Número de Publicaciones\") +\n  ggtitle(\"Relación entre Seguidores y Publicaciones\")\n\n\n\n\nHemos avanzado algo, pero muy poco siendo objetivos. Seguimos sin ver nada, ya que se aprecia claramente una contundente densidad de puntos en la parte inferior izquierda, problamente por la distribución de los datos con los que estamos trabajando. ¿Qué podemos hacer entonces? No hay por qué alterarnos, todo tiene solución, y más aún en el mundo del análisis de datos. Vamos a optar por cambiar la escala de nuestros datos, para ver si así logramos algo. Concretamente, la escala logarítmica puede ser útil cuando tienes datos con una distribución sesgada o con valores extremadamente grandes que dificultan la visualización de los detalles en la parte inferior de la escala. Por ello usamos scale_x(y)_log10.\n\nggplot(all_data, aes(x = `#followers`, y = `#posts`)) +\n  geom_point(color = \"darkblue\") +\n  labs(x = \"Número de Seguidores\", y = \"Número de Publicaciones\") +\n  ggtitle(\"Relación entre Seguidores y Publicaciones\") +\n  scale_x_log10(breaks = 2^seq(0, 24, by = 1),labels = scales::comma) + # Escala logarítmica en base 10 para el eje x\n  scale_y_log10(labels = scales::comma) + # Escala logarítmica en base 10 para el eje y\n  theme(plot.title = element_text(hjust = 0.5),\n        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n¡Esto ya es otra cosa! Ahora podemos ver mucho mejor las cosas. La aplicación de una escala logarítmica en este gráfico ha permitido una representación más clara y efectiva de los datos, especialmente cuando se trata de valores que abarcan varios órdenes de magnitud. Sin embargo, es importante tener en cuenta que los valores que aparecen en los ejes no son los reales, sino los convertidos mediante la escala logarítmica. Por lo tanto, se debe ejercer cautela al interpretar los valores representados en el gráfico. Es decir, si quisieramos obtener de vuelta dichos valores reales a partir de los visualizados en la gráfica, deberíamos realizar la operación inversa a la escala realizada.\nPodríamos probar también a representar una gráfica donde la inferencia o eje Y correspondiera a la variable que realmente esta modelandose a lo largo de todo el análisis de datos de este dataset, fake. Para ello:\n\nggplot(all_data, aes(x = `#followers`, y = `fullname words`, color = as.factor(fake))) +\n  geom_point() +\n  labs(x = \"Número de Seguidores\", y = \"Número de Palabras en el Nombre Completo\", color = \"Fake\") +\n  ggtitle(\"Relación entre Seguidores, Palabras en el Nombre Completo y Fake\") +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  scale_x_log10() + scale_y_log10()\n\n\n\n\nPodemos ver claramente en el gráfico como existe una separación notable entre cuentas fake y no fake en funcion del número de seguidores que tienen, aunque no es tan significante el número de palabtas en el nombre completo. Podemos probar a modelarlo en función de otros atributos…\n\nggplot(all_data, aes(x = `#follows`, y = `profile pic`, color = as.factor(fake))) +\n  geom_point() +\n  labs(x = \"Número de Seguidos\", y = \"¿Tiene foto de perfil?\", color = \"Fake\") +\n  ggtitle(\"Relación entre Seguidores, Palabras en el Nombre Completo y Fake\") +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  scale_x_log10()\n\n\n\n\nSe aprecia como en el caso de las cuentas que no presentan foto de perfil, no importa el número de seguidores que tengan ya que podemos asegurar casi al 100% de firmeza que se va a tratar de una cuenta falsa, lo cual es lógico pensar. En el caso de las cuentas que si presentan fotos en su cuenta, la distribución de cuentas fake es más complicada de ver.\n\nggplot(data = subset(all_data, `profile pic` == 1), aes(x = `#follows`, y = `description length`, color = as.factor(fake))) +\n  geom_point() +\n  labs(x = \"Número de Seguidos\", y = \"Longitud de la descripcion de la cuenta\", color = \"Fake\") +\n  ggtitle(\"Relación entre Seguidores, Palabras en el Nombre Completo y Fake\") +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  scale_x_log10() + scale_y_log10()\n\n\n\n\nAhora vemos información mucho más útil de la cual poder extraer conocimiento. Se ve claramente en la parte superior derecha del gráfico un extensa densidad de puntos azules (cuentas verdades de Instagram), que corresponden a un intervalo aproximado (ignorando samples anómalos) de entre 100 y 1000 seguidos en su cuenta, y 8 y 110 palabra en la descripcion de dichas cuentas, lo cual es realmente lógico para nosotros. Cuando el número de palabras en la descripción es 0, es mucho más probable que estemos hablando de cuentas no verdaderas:\n\n# Contar el número de cuentas fake y no fake con description length igual a 0\ntable(subset(all_data, `description length` == 0)$fake)\n\n\n  0   1 \n 91 304 \n\n\nVemos que concretamente son 304 cuentas las que son fake cuando la descripción de sus cuentas es vacía, frente a 91 verdaderas.\nExiste otra herramienta de interes en el área de visualización de datasets (así como en regresión, por ejemplo) que es pairs(). Se trata de una herramienta versátil y poderosa utilizada en el análisis exploratorio de datos y la visualización. Su función principal es crear una matriz de gráficos de dispersión, lo que permite explorar las relaciones entre múltiples variables en un conjunto de datos de manera eficiente. Genera una cuadrícula de gráficos de dispersión donde cada celda representa la relación entre dos variables del conjunto de datos.\n\npairs(all_data, col = \"salmon\")\n\n\n\n\nGgplot también permite hacer uso de geom_smooth para simular un modelo linear de regresión sobre las variables que le indicamos. Sin embargo, no termina de ser demasiada útil, y más tarde en el apartado de regresión explotaremos de manera más inteligente este tipo de técnicas.\n\n# Gráfico de dispersión de seguidores vs. publicaciones con línea de tendencia\nggplot(all_data, aes(x = `#posts`, y = `#followers`)) +\n  geom_point(color = \"darkblue\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +  # Agregar línea de tendencia\n  labs(x = \"Número de Publicaciones\", y = \"Número de Seguidores\") +\n  ggtitle(\"Relación entre Seguidores y Publicaciones con Línea de Tendencia\") + scale_x_log10() + scale_y_log10()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nPodríamos hacer un único gráfico, que se componga a su vez de otros 2 subgráficos. Esto lo lograremos haciendo uso de facet_grid. Concretamente, haremos la división a partir de si los datos presentan fotos en su perfil.\n\nggplot(all_data) +\n  geom_point(aes(x = `#followers`, y = `nums/length username`, color = `fake`)) +\n  scale_x_log10() + scale_y_log10() +\n  facet_grid(rows = vars(`profile pic`))\n\n\n\n\nO incluso podríamos ir un paso más alla. Discretizando alguno de los atributos de nuestro dataset y añadiendo más separación de subgráficos. ¡Vamos a ello!\n\nall_data_discretizado &lt;- all_data\n\nall_data_discretizado$`description length` &lt;- cut(all_data_discretizado$`description length`, breaks = 3, labels = c(\"Poca\", \"Media\", \"Mucha\"))\n\nggplot(all_data_discretizado) +\n  geom_point(aes(x = `#followers`, y = `nums/length username`, color = `fake`)) +\n  scale_x_log10() + scale_y_log10() +\n  facet_grid(rows = vars(`profile pic`), cols = vars(`description length`))\n\n\n\n\nEsta composición de gráficos nos permite sacar varias conclusiones visual y rapidamente. Por un lado nos podemos centrar en la primera columna. Se trata de un subplot filtrado para aquellas filas de nuestro dataset que presentan una longitud de descripcion corta (la gran mayoría del dataset por lo que podemos ver). Dentro de esta columna del subplot, se ve claramente, como ya habíamos concluido antes, que las cuentas que no tienen foto de perfil son siempre falsas, y si tienen, la distribución entonces está un poco más repartida. En el caso de las otras columnas (descripciones medias y altas), en la gran mayoría de los datos se trata de cuentas verdaderas, salvo casos excepcionales.\nAhora que hemos explorado a fondo nuestros datos a través de diversas técnicas de visualización, podemos pasar a la interesante sección de reglas de asociación. En esta fase, nos adentraremos en el mundo de las relaciones y patrones ocultos en nuestros datos, utilizando técnicas avanzadas para descubrir insights valiosos."
  },
  {
    "objectID": "analisisexploratorio.html#un-poco-de-x-me-gustaria-aquí-meter-otro-punto",
    "href": "analisisexploratorio.html#un-poco-de-x-me-gustaria-aquí-meter-otro-punto",
    "title": "1  Análisis exploratorio de datos",
    "section": "1.2 Un poco de X (me gustaria aquí meter otro punto)",
    "text": "1.2 Un poco de X (me gustaria aquí meter otro punto)\nBlablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla Blablabla.\nConsidero que los pasos dados hasta ahora pueden conformar de manera completa un análisis exploratorio de datos del dataset que nos concierne. Sin embargo, esto no ha hecho más que empezar, porque los métodos de visualización vistos en la asignatura nos van a permitir ver de manera visual y clara todo lo que hemos ido detallando con “dplyr”, y mucho más…"
  },
  {
    "objectID": "analisisexploratorio.html#un-poco-de-summarytools",
    "href": "analisisexploratorio.html#un-poco-de-summarytools",
    "title": "1  Análisis exploratorio de datos",
    "section": "1.2 Un poco de summarytools",
    "text": "1.2 Un poco de summarytools\nEn el vasto universo del análisis de datos, navegar por conjuntos de datos complejos puede ser como aventurarse en un laberinto sin un mapa claro. ¿Cómo podemos destilar la esencia de nuestros datos de manera eficiente y efectiva? Ahí es donde entra en juego summarytools, un nuevo amigo en el camino del análisis de datos, no impartido durante la asignatura, pero que considero que puede estar interesante mencionar y utilizar, aunque en menor medida.\nPero, ¿qué hace que summarytools sea tan especial? Es como tener a un experto en análisis de datos a tu lado, pero sin la jerga complicada y los gráficos confusos. Con solo unas pocas líneas de código, summarytools te ofrece un resumen claro y conciso de tus datos, desde estadísticas descriptivas hasta tablas de frecuencia y matrices de correlación.\n\nlibrary(summarytools)\n\n\ndescr(all_data)\n\nDescriptive Statistics  \nall_data  \nN: 696  \n\n                     #followers   #follows    #posts   description length   external URL     fake\n----------------- ------------- ---------- --------- -------------------- -------------- --------\n             Mean      79149.91     555.09    103.24                23.41           0.11     0.50\n          Std.Dev     842887.54    1023.61    378.03                38.60           0.32     0.50\n              Min          0.00       0.00      0.00                 0.00           0.00     0.00\n               Q1         42.00      61.00      0.00                 0.00           0.00     0.00\n           Median        165.50     252.00      9.00                 0.00           0.00     0.50\n               Q3        695.00     602.50     77.00                35.00           0.00     1.00\n              Max   15338538.00    7500.00   7389.00               150.00           1.00     1.00\n              MAD        223.13     320.98     13.34                 0.00           0.00     0.74\n              IQR        651.00     540.75     77.00                35.00           0.00     1.00\n               CV         10.65       1.84      3.66                 1.65           2.80     1.00\n         Skewness         14.35       4.39     13.08                 1.79           2.43     0.00\n      SE.Skewness          0.09       0.09      0.09                 0.09           0.09     0.09\n         Kurtosis        225.93      22.84    223.13                 2.33           3.92    -2.00\n          N.Valid        696.00     696.00    696.00               696.00         696.00   696.00\n        Pct.Valid        100.00     100.00    100.00               100.00         100.00   100.00\n\nTable: Table continues below\n\n \n\n                    fullname words   name==username   nums/length fullname   nums/length username\n----------------- ---------------- ---------------- ---------------------- ----------------------\n             Mean             1.48             0.04                   0.04                   0.17\n          Std.Dev             1.08             0.19                   0.14                   0.22\n              Min             0.00             0.00                   0.00                   0.00\n               Q1             1.00             0.00                   0.00                   0.00\n           Median             1.00             0.00                   0.00                   0.00\n               Q3             2.00             0.00                   0.00                   0.33\n              Max            12.00             1.00                   1.00                   0.92\n              MAD             1.48             0.00                   0.00                   0.00\n              IQR             1.00             0.00                   0.00                   0.33\n               CV             0.73             5.18                   3.41                   1.31\n         Skewness             3.32             4.98                   4.31                   1.26\n      SE.Skewness             0.09             0.09                   0.09                   0.09\n         Kurtosis            23.01            22.80                  21.41                   0.99\n          N.Valid           696.00           696.00                 696.00                 696.00\n        Pct.Valid           100.00           100.00                 100.00                 100.00\n\nTable: Table continues below\n\n \n\n                    private   profile pic\n----------------- --------- -------------\n             Mean      0.37          0.71\n          Std.Dev      0.48          0.45\n              Min      0.00          0.00\n               Q1      0.00          0.00\n           Median      0.00          1.00\n               Q3      1.00          1.00\n              Max      1.00          1.00\n              MAD      0.00          0.00\n              IQR      1.00          1.00\n               CV      1.31          0.64\n         Skewness      0.54         -0.93\n      SE.Skewness      0.09          0.09\n         Kurtosis     -1.71         -1.14\n          N.Valid    696.00        696.00\n        Pct.Valid    100.00        100.00\n\n\nAl ejecutar el comando descr() para obtener estadísticas descriptivas de nuestro conjunto de datos all_data, hemos obtenido una visión completa de las características numéricas y categóricas que lo componen. (696 observaciones)\nEl resumen descriptivo revela que las cuentas tienen, en promedio, alrededor de 79150 seguidores, 555 seguidos y 103 publicaciones. Se observa una gran variabilidad en las estadísticas, con desviaciones estándar significativas. La distribución de las métricas varía ampliamente, demostrado por los valores mínimo y máximo, así como los cuartiles y la mediana.\n\nfreq(all_data$private)\n\nFrequencies  \nall_data$private  \nType: Numeric  \n\n              Freq   % Valid   % Valid Cum.   % Total   % Total Cum.\n----------- ------ --------- -------------- --------- --------------\n          0    439     63.07          63.07     63.07          63.07\n          1    257     36.93         100.00     36.93         100.00\n       &lt;NA&gt;      0                               0.00         100.00\n      Total    696    100.00         100.00    100.00         100.00\n\n\nAl ejecutar freq(all_data$private), obtenemos una visión detallada de la distribución de la variable private en nuestro conjunto de datos. La mayoría de las cuentas (439, 63.07%) son públicas (valor 0), mientras que 257 cuentas (36.93%) son privadas (valor 1). No hay valores faltantes para esta variable. Esta información nos permite comprender mejor la proporción de cuentas públicas y privadas en nuestro conjunto de datos.\n\n# Matriz de correlación para variables numéricas\ncor_matrix &lt;- cor(select(all_data, -c(`profile pic`, `fullname words`, `name==username`, `description length`, `external URL`, `private`, `fake`)))\n\n# Resumen descriptivo de la matriz de correlación\ndescr(cor_matrix)\n\nDescriptive Statistics  \n\n                    #followers   #follows   #posts   nums/length fullname   nums/length username\n----------------- ------------ ---------- -------- ---------------------- ----------------------\n             Mean         0.25       0.18     0.25                   0.27                   0.22\n          Std.Dev         0.45       0.47     0.46                   0.47                   0.51\n              Min        -0.06      -0.17    -0.16                  -0.06                  -0.17\n               Q1        -0.03      -0.05    -0.06                  -0.05                  -0.16\n           Median         0.02       0.02     0.11                  -0.03                  -0.06\n               Q3         0.34       0.11     0.34                   0.47                   0.47\n              Max         1.00       1.00     1.00                   1.00                   1.00\n              MAD         0.12       0.14     0.34                   0.05                   0.15\n              IQR         0.37       0.17     0.41                   0.52                   0.63\n               CV         1.76       2.56     1.87                   1.76                   2.37\n         Skewness         0.78       0.95     0.66                   0.61                   0.55\n      SE.Skewness         0.91       0.91     0.91                   0.91                   0.91\n         Kurtosis        -1.35      -1.07    -1.43                  -1.65                  -1.74\n          N.Valid         5.00       5.00     5.00                   5.00                   5.00\n        Pct.Valid       100.00     100.00   100.00                 100.00                 100.00\n\n\nAl calcular la matriz de correlación entre algunas variables numéricas en nuestro conjunto de datos, observamos varias tendencias y relaciones interesantes. Las métricas descriptivas revelan que las variables tienen diferentes grados de variabilidad y distribución.\nEl análisis de correlación revela que las variables tienen correlaciones moderadas en promedio (alrededor de 0.25), con una amplia dispersión indicada por la desviación estándar. Las correlaciones varían entre -0.06 y 1.00, sugiriendo una variedad de relaciones lineales y no lineales entre las variables. Además, la asimetría y la curtosis proporcionan información sobre la distribución de las correlaciones, destacando diferencias en la dispersión entre los pares de variables.\n\ndfSummary(all_data)\n\nData Frame Summary  \nall_data  \nDimensions: 696 x 12  \nDuplicates: 4  \n\n-----------------------------------------------------------------------------------------------------------------------------\nNo   Variable               Stats / Values                   Freqs (% of Valid)    Graph                 Valid      Missing  \n---- ---------------------- -------------------------------- --------------------- --------------------- ---------- ---------\n1    profile pic            Min  : 0                         0 : 201 (28.9%)       IIIII                 696        0        \n     [numeric]              Mean : 0.7                       1 : 495 (71.1%)       IIIIIIIIIIIIII        (100.0%)   (0.0%)   \n                            Max  : 1                                                                                         \n\n2    nums/length username   Mean (sd) : 0.2 (0.2)            58 distinct values    :                     696        0        \n     [numeric]              min &lt; med &lt; max:                                       :                     (100.0%)   (0.0%)   \n                            0 &lt; 0 &lt; 0.9                                            :                                         \n                            IQR (CV) : 0.3 (1.3)                                   :                                         \n                                                                                   : : . : : . .                             \n\n3    fullname words         Mean (sd) : 1.5 (1.1)            11 distinct values    :                     696        0        \n     [numeric]              min &lt; med &lt; max:                                       :                     (100.0%)   (0.0%)   \n                            0 &lt; 1 &lt; 12                                             : :                                       \n                            IQR (CV) : 1 (0.7)                                     : :                                       \n                                                                                   : : .                                     \n\n4    nums/length fullname   Mean (sd) : 0 (0.1)              27 distinct values    :                     696        0        \n     [numeric]              min &lt; med &lt; max:                                       :                     (100.0%)   (0.0%)   \n                            0 &lt; 0 &lt; 1                                              :                                         \n                            IQR (CV) : 0 (3.4)                                     :                                         \n                                                                                   :                                         \n\n5    name==username         Min  : 0                         0 : 671 (96.4%)       IIIIIIIIIIIIIIIIIII   696        0        \n     [numeric]              Mean : 0                         1 :  25 ( 3.6%)                             (100.0%)   (0.0%)   \n                            Max  : 1                                                                                         \n\n6    description length     Mean (sd) : 23.4 (38.6)          114 distinct values   :                     696        0        \n     [numeric]              min &lt; med &lt; max:                                       :                     (100.0%)   (0.0%)   \n                            0 &lt; 0 &lt; 150                                            :                                         \n                            IQR (CV) : 35 (1.6)                                    :                                         \n                                                                                   : . . . .                                 \n\n7    external URL           Min  : 0                         0 : 617 (88.6%)       IIIIIIIIIIIIIIIII     696        0        \n     [numeric]              Mean : 0.1                       1 :  79 (11.4%)       II                    (100.0%)   (0.0%)   \n                            Max  : 1                                                                                         \n\n8    private                Min  : 0                         0 : 439 (63.1%)       IIIIIIIIIIII          696        0        \n     [numeric]              Mean : 0.4                       1 : 257 (36.9%)       IIIIIII               (100.0%)   (0.0%)   \n                            Max  : 1                                                                                         \n\n9    #posts                 Mean (sd) : 103.2 (378)          211 distinct values   :                     696        0        \n     [numeric]              min &lt; med &lt; max:                                       :                     (100.0%)   (0.0%)   \n                            0 &lt; 9 &lt; 7389                                           :                                         \n                            IQR (CV) : 77 (3.7)                                    :                                         \n                                                                                   :                                         \n\n10   #followers             Mean (sd) : 79149.9 (842887.5)   435 distinct values   :                     696        0        \n     [numeric]              min &lt; med &lt; max:                                       :                     (100.0%)   (0.0%)   \n                            0 &lt; 165.5 &lt; 15338538                                   :                                         \n                            IQR (CV) : 651 (10.6)                                  :                                         \n                                                                                   :                                         \n\n11   #follows               Mean (sd) : 555.1 (1023.6)       468 distinct values   :                     696        0        \n     [numeric]              min &lt; med &lt; max:                                       :                     (100.0%)   (0.0%)   \n                            0 &lt; 252 &lt; 7500                                         :                                         \n                            IQR (CV) : 540.8 (1.8)                                 :                                         \n                                                                                   : .                                       \n\n12   fake                   Min  : 0                         0 : 348 (50.0%)       IIIIIIIIII            696        0        \n     [numeric]              Mean : 0.5                       1 : 348 (50.0%)       IIIIIIIIII            (100.0%)   (0.0%)   \n                            Max  : 1                                                                                         \n-----------------------------------------------------------------------------------------------------------------------------\n\n\nEl resumen detallado de all_data proporcionado por dfSummary() ofrece una visión completa de las características y distribuciones de las variables en nuestro conjunto de datos. Este resumen incluye estadísticas descriptivas, tablas de frecuencia y métricas adicionales que nos ayudan a comprender la naturaleza de nuestros datos. Con esta información, estamos mejor equipados para realizar análisis más profundos y tomar decisiones informadas basadas en la comprensión completa de nuestro conjunto de datos.\nConsidero que los pasos dados hasta ahora pueden conformar de manera completa un análisis exploratorio de datos del dataset que nos concierne. Sin embargo, esto no ha hecho más que empezar, porque los métodos de visualización vistos en la asignatura nos van a permitir ver de manera visual y clara todo lo que hemos ido detallando con “dplyr” o “summarytools”, y mucho más…"
  },
  {
    "objectID": "regresion.html#residuals-residuos",
    "href": "regresion.html#residuals-residuos",
    "title": "5  Regresión",
    "section": "5.1 Residuals (Residuos)",
    "text": "5.1 Residuals (Residuos)\nEsta sección muestra las estadísticas resumidas de los residuos del modelo. Los residuos son las diferencias entre los valores observados y los valores predichos por el modelo. Se presentan estadísticas como el mínimo, el primer cuartil, la mediana, el tercer cuartil y el máximo de los residuos."
  },
  {
    "objectID": "regresion.html#coefficients-coeficientes",
    "href": "regresion.html#coefficients-coeficientes",
    "title": "5  Regresión",
    "section": "5.2 Coefficients (Coeficientes)",
    "text": "5.2 Coefficients (Coeficientes)\nEsta tabla muestra los coeficientes estimados para cada variable predictora en el modelo. Para cada variable, se proporciona una estimación del coeficiente, el error estándar del coeficiente, el valor t y el valor p asociado con la prueba de hipótesis de que el coeficiente es igual a cero. Los valores t y los valores p ayudan a determinar si una variable es significativa para predecir la variable de respuesta. Además, los coeficientes estimados proporcionan información sobre la dirección y la magnitud de la relación entre las variables predictoras y la variable de respuesta."
  },
  {
    "objectID": "regresion.html#residual-standard-error-error-estándar-de-los-residuos",
    "href": "regresion.html#residual-standard-error-error-estándar-de-los-residuos",
    "title": "5  Regresión",
    "section": "5.3 Residual standard error (Error estándar de los residuos)",
    "text": "5.3 Residual standard error (Error estándar de los residuos)\nEsta es una estimación de la desviación estándar de los residuos del modelo. Indica cuánto varían los valores observados de la variable de respuesta alrededor de los valores predichos por el modelo."
  },
  {
    "objectID": "regresion.html#multiple-r-squared-r-cuadrado-múltiple",
    "href": "regresion.html#multiple-r-squared-r-cuadrado-múltiple",
    "title": "5  Regresión",
    "section": "5.4 Multiple R-squared (R cuadrado múltiple)",
    "text": "5.4 Multiple R-squared (R cuadrado múltiple)\nEste es el coeficiente de determinación, que indica la proporción de la variabilidad en la variable de respuesta que es explicada por el modelo. Cuanto más cercano sea el R cuadrado a 1, mejor se ajusta el modelo a los datos."
  }
]