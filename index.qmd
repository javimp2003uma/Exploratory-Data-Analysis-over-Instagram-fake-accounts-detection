# Introducción {.unnumbered}

Son múltiples las técnicas sobre análisis de datos que hemos aprendido a lo largo de la asignatura de "Laboratorio de Computación Científica", entre las cuales podemos mencionar: análisis de conjuntos de datos con [dplyr](https://rpubs.com/joser/dplyr/), visualización de datos con [ggplot](https://rpubs.com/daniballari/ggplot) o reglas de asociación de un dataset con [apriori](https://www.rdocumentation.org/packages/arules/versions/1.6-1/topics/apriori). Se que en este pequeño listado dejo atrás muchas de las herramientas que hemos ido usando a lo largo de la asignatura, pero sin duda en este proyecto abordaremos sus aplicaciones.

El análisis de datos y las técnicas asociadas tienen una amplia gama de aplicaciones en diversos campos, lo que los convierte en herramientas fundamentales para la toma de decisiones informadas y la generación de conocimiento. Entre ellas podemos destacar: **investigación científica** (identificar patrones y analizar resultados experimentales), **sectores empresariales** (comprender el comportamiento del mercado en ciertos ámbitos), **salud y medicina** (predecir enfermedades) o **marketing** (identificar perfiles destacados de clientes).

Sin embargo, nosotros nos iremos un poco más a terreno "moderno" y actual. Hablamos de [Instagram](https://es.wikipedia.org/wiki/Instagram). ¿Quién no utiliza esta reconocidísima red social hoy en día? Y sobretodo, enfocados a lo que nos concierne a nuestro proyecto, **¿quién no ha sospechado alguna vez de un usuario desconocido, que por alguna razón extraña comienza a seguirnos?**. Aquí centraremos nuestra investigación. Trataremos de analizar un amplio dataset de la plataforma [Kaggle](https://www.kaggle.com/).

Se trata concretamente de un [dataset](https://www.kaggle.com/code/durgeshrao9993/fake-instagram-profile-detection-model/notebook) que contiene información de 696 usuarios de *Instagram*, para los cuales proporciona un total de 12 atributos, entre los cuales destacan: *nums/length username*, *fullname words*, *name==username* , *#follows* o *fake* (el más importante o como se le suele llamar en el contexto de [Machine Learning](https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico), la inferencia, es decir, aquello que el modelo predice). Es precisamente en este último campo en el que realmente el dataset está centrado, ya que en la propia documentación se indica que se pretende construir un modelo de aprendizaje automático fiable, que aprenda del conjunto de datos (*training set*), y sea capaz tras este proceso de predecir para ciertas entradas (*testing data*) que representen a usuario no conocidos anteriormente por el modelo, si se tratan de cuentas verdaderas o falsas. Aunque en nuestro caso el proyecto se aleja un poco de las manos del ML (Machine Learning) y solo se pretende usar el dataset para aplicarlo a lo que nos concierne, en mi caso trataré de incluir alguna sección que este orientada a este campo.

[![](images/1.jpg)](https://later.com/blog/fake-instagram-account/)

Cabe mencionar por último, que para la realización del trabajo haremos uso de [Quarto](https://quarto.org/), una poderosa herramienta diseñada para la creación y gestión de libros interactivos y dinámicos. Con su enfoque centrado en el usuario y su versatilidad, Quarto permite a los creadores transformar ideas en conocimiento de manera eficiente y efectiva. Los books son una forma eficaz de compartir conocimiento, desde documentos técnicos y manuales de referencia hasta tutoriales interactivos y libros educativos.

Una vez hemos descrito con detalle el problema a abordar, podemos pasar al primer punto del proyecto, que consistirá en un [análisis explotario de datos](analisisexploratorio.html) centrados en nuestro dataset.
